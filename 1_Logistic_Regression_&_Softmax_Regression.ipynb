{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"1_Logistic_Regression_&_Softmax_Regression.ipynb","provenance":[],"collapsed_sections":["4e3JORB8PEfL","VpXPqYoQzOod"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3LGpbq4tSiOw"},"source":["# Logistic Regression & Softmax Regression"]},{"cell_type":"markdown","metadata":{"id":"1e8vwb3zTACs"},"source":["## Tóm tắt nội dung\n","Trong bài tập này, các bạn sẽ sử dụng kiến thức đã học về logistic regression và softmax regression để giải quyết bài toán phân lớp."]},{"cell_type":"markdown","metadata":{"id":"TbebJwTgTC9a"},"source":["## Giới thiệu"]},{"cell_type":"markdown","metadata":{"id":"kESB1ROATIF7"},"source":["Để có thể hoàn tất bài tập này, các bạn cần nắm rõ những kiến thức sau: \n","- Logistic regression là gì, nguyên tắc hoạt động ra sao.\n","- Softmax regression là gì và nguyên tắc hoạt động.\n","- Cách lấy đạo hàm cho các tham số trong hai mô hình trên.\n","- Giải thuật gradient descent.\n","\n","Bạn có thể tham khảo lại bài giảng của lớp để nắm vững các nội dung này. Ngoài ra, các bạn có thể đặt câu hỏi cho đội ngũ giảng dạy nếu có thắc mắc.\n","\n","Bài tập này sẽ gồm có hai bài chính:\n","- Bài 1: phân loại hai lớp dùng **logistic regression**.\n","- Bài 2: phân loại 10 lớp dùng **softmax regression**.\n","\n","Yêu cầu dành cho các bạn trong là giải quyết hai bài trên bằng **cả numpy và TensorFlow**.\n","\n","*Lưu ý: để tiện cho việc phân biệt giữa lớp python và lớp trong bài toán phân loại, người viết qui ước rằng khi viết **class** nghĩa là đang nói về python class, khi viết lớp nghĩa là đang ám chỉ **lớp** của dữ liệu cần phân loại*."]},{"cell_type":"markdown","metadata":{"id":"eLgPOx1DpSwb"},"source":["## Hướng dẫn làm và nộp bài\n","Ở mỗi bài tập, các bạn sẽ được yêu cầu điền phần còn thiếu vào trong hàm, các cell để thực hiện phần bài làm sẽ có dòng đầu tiên như sau:\n","```python\n","# GRADED FUNCTION: <tên hàm>\n","...\n","```\n","Trong cell đó, các bạn sẽ code phần đáp án của mình giữa 2 phần:\n","```python\n","### START CODE HERE ###\n","<phần bài làm>\n","### END CODE HERE ###\n","```\n","\n","Sau khi thực hiện xong các bạn cần upload file bài làm .ipynb theo hướng dẫn ở [form này](https://docs.google.com/forms/d/e/1FAIpQLSfJWhmjCJhMlxXSjiolwKoh88KxZv4oZLNCLxui2f2gnmS1Hg/viewform?usp=sf_link)."]},{"cell_type":"markdown","metadata":{"id":"pJ1iE641TaNY"},"source":["## Tải dữ liệu và các hàm cần thiết"]},{"cell_type":"markdown","metadata":{"id":"Gq7TH8EETxtM"},"source":["Các bạn chạy cell bên dưới để tải bộ dữ liệu cũng như các hàm dùng để test cách cài đặt của các bạn:"]},{"cell_type":"code","metadata":{"id":"QxnfQZEGTw2k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d1b54e4-a02b-4f10-e438-ebead7d5c067"},"source":["from google_drive_downloader import GoogleDriveDownloader as gdd\n","gdd.download_file_from_google_drive(file_id='1I0S1vp6RxDtphOwVynpfPPfMzcvmC8OC', dest_path='./Assignment1.zip', unzip=True)\n","!rm Assignment1.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading 1I0S1vp6RxDtphOwVynpfPPfMzcvmC8OC into ./Assignment1.zip... Done.\n","Unzipping...Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ETwlnPvIUQEo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a3b6e16d-2849-4f0c-9277-6dc36ff474fe"},"source":["!ls Assignment1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fashion-mnist  logistic_unittest.npy  softmax_unittest.npy  vehicles.dat\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eLhpVBs6K53J"},"source":["Dữ liệu tải xuống bao gồm:\n","* File `vehicles.dat`: dữ liệu cho bài tập 1.\n","* Folder `fashion-mnist`: dữ liệu cho bài tập 2.\n","* Các files `logistic_unittest.npy` và `softmax_unittest.npy`: được dùng để kiểm tra một số hàm các bạn cài đặt."]},{"cell_type":"markdown","metadata":{"id":"caPRYRLnVwu8"},"source":["## Các hàm bổ trợ dùng để đọc dữ liệu\n","\n","Nhóm TA sẽ giúp bạn định nghĩa các hàm bổ trợ trong việc đọc dữ liệu, các bạn không cần chỉnh sửa các hàm này:"]},{"cell_type":"code","metadata":{"id":"1gHJ1OZONpud","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ec258e8-f70b-4822-cea9-c5ce453347b7"},"source":["# GRADED FUNCTION\n","import pickle\n","import gzip\n","import glob\n","import numpy as np\n","import tensorflow as tf\n","import sys\n","import inspect\n","print(\"Tensorflow version: \", tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensorflow version:  2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1JV27SB0l0fD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"47c801c8-2a5e-4a2a-a2d9-774b9a3bba0c"},"source":["%pylab inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LGG6cXOPVPB2"},"source":["\"\"\"\n","These functions help you read data from data files.\n","Author: Kien Huynh\n","\"\"\"\n","\n","\n","def load_npy(file_name):\n","    \"\"\"load_npy\n","    Load numpy data file. This is needed as python 2.7 pickle uses ascii as default encoding method but python 3.x uses utf-8.abs.\n","\n","    :param file_name: npy file path\n","    \n","    :return obj: loaded numpy object\n","    \"\"\"\n","    \n","    if (sys.version_info[0] >= 3):\n","        obj = np.load(file_name, encoding='latin1',allow_pickle=True)\n","    elif (sys.version_info[0] >=2):\n","        obj = np.load(file_name)\n","    \n","    return obj\n","\n","def testcase_check(your_arr, test_arr, testname, print_all, print_ind=None):\n","    eps = 0.00001\n","    if (type(your_arr) != type(test_arr)):\n","        print(\"Testing %s: Failed. Your arr should be %s but it is %s instead.\" % (testname, type(test_arr), type(your_arr)))\n","        \n","    \n","    if (your_arr.shape != test_arr.shape):\n","        print(\"Testing %s: Failed. Your arr should have a shape of %s but its shape is %s instead.\" % (testname, test_arr.shape, your_arr.shape))\n","        \n","\n","    if (np.sum((your_arr-test_arr)**2) < eps):\n","        print(\"Testing %s: Passed.\" % testname)\n","    else:\n","        print(\"Testing %s: Failed.\" % testname)\n","        if (print_all): \n","            print(\"Your array is\")\n","            print(your_arr)\n","            print(\"\\nWhile it should be\")\n","            print(test_arr)\n","        else:\n","            print(\"The first few rows of your array are\")\n","            print(your_arr[print_ind, 0])\n","            print(\"\\nWhile they should be\")\n","            print(test_arr[print_ind, 0])\n","    \n","    print(\"----------------------------------------\")\n","\n","def load_list(file_name):\n","    \"\"\"load_list\n","    Load a list object to file_name.\n","\n","    :param file_name: string, file name\n","    \"\"\"\n","    end_of_file = False\n","    list_obj = [] \n","    f = open(file_name, 'rb')\n","    python_version = sys.version_info[0]\n","    while (not end_of_file):\n","        try:\n","            if (python_version >= 3):\n","                list_obj.append(pickle.load(f, encoding='latin1'))\n","            elif (python_version >=2):\n","                list_obj.append(pickle.load(f))\n","        except EOFError:\n","            end_of_file = True\n","            print(\"EOF Reached\")\n","\n","    f.close()\n","    return list_obj  \n","\n","\n","def get_vehicle_data():\n","    \"\"\"\n","    Load vehicle data and return it as a list: [train_x, train_y, test_x, test_y].\n","    \"\"\"\n","    print('Reading vehicle data...')\n","    train_x, train_y, test_x, test_y = load_list('./Assignment1/vehicles.dat')\n","    train_x = np.transpose(train_x, (2,0,1))\n","    test_x = np.transpose(test_x, (2,0,1)) \n","\n","    print('Done reading')\n","    return train_x, train_y, test_x, test_y\n","\n","\n","def read_mnist_gz(data_path, offset):\n","    with gzip.open(data_path, 'rb') as f:\n","        dataset = np.frombuffer(f.read(), dtype=np.uint8, offset=offset)\n","\n","    return dataset\n","\n","\n","def get_mnist_data(sampling_step=20):\n","    print('Reading fashion MNIST data...')\n","    train_x = read_mnist_gz('./Assignment1/fashion-mnist/train-images-idx3-ubyte.gz', 16)\n","    train_y = read_mnist_gz('./Assignment1/fashion-mnist/train-labels-idx1-ubyte.gz', 8)\n","    test_x = read_mnist_gz('./Assignment1/fashion-mnist/t10k-images-idx3-ubyte.gz', 16)\n","    test_y = read_mnist_gz('./Assignment1/fashion-mnist/t10k-labels-idx1-ubyte.gz', 8)\n","    num_train = len(train_y)\n","    num_test = len(test_y)\n","\n","    train_x = train_x.reshape((num_train, 28*28))\n","    test_x = test_x.reshape((num_test, 28*28))\n","\n","    val_x = train_x[50000:,:]\n","    val_y = train_y[50000:]\n","    train_x = train_x[:50000,:]\n","    train_y = train_y[:50000]\n","\n","    train_x = train_x[0::sampling_step,:]\n","    train_y = train_y[0::sampling_step]\n","    val_x = val_x[0::sampling_step,:]\n","    val_y = val_y[0::sampling_step]\n","    test_x = test_x[0::sampling_step,:]\n","    test_y = test_y[0::sampling_step]\n","    return train_x.astype(np.float32), train_y, val_x.astype(np.float32), val_y, test_x.astype(np.float32), test_y\n","\n","\n","def logistic_unit_test():\n","  train_x, train_y, test_x, test_y = get_vehicle_data()\n","  x = logistic_test_case[\"train_x1\"]\n","  y = train_y[0:5,:]\n","  learning_rate = 0.001\n","  momentum_rate = 0.9\n","  for i in range(10):\n","    test_dict = logistic_test_case[\"output\"][i]\n","    classifier = LogisticClassifier((x.shape[1],1))\n","    classifier.w = test_dict[\"w\"]\n","\n","    y_hat = classifier.feed_forward(x)\n","    testcase_check(y_hat, test_dict[\"y_hat\"], \"feed_forward %d\" % (i+1), True)\n","    loss = classifier.compute_loss(y, y_hat)\n","    testcase_check(loss, test_dict[\"loss\"], \"compute_loss %d\" % (i+1), True)\n","    grad = classifier.get_grad(x, y, y_hat)\n","    testcase_check(grad, test_dict[\"grad\"], \"get_grad %d\" % (i+1), True)\n","    classifier.update_weight(grad,0.001)\n","    testcase_check(classifier.w, test_dict[\"w_1\"], \"update_weight %d\" % (i+1), True)\n","    momentum = np.ones_like(test_dict[\"grad\"])\n","    classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n","    testcase_check(classifier.w, test_dict[\"w_2\"], \"update_weight_momentum %d\" % (i+1), True)\n","    logistic_test_case[\"output\"].append(test_dict)\n","\n","\n","def softmax_unit_test():\n","  train_x, train_y, _, _, _, _ = get_mnist_data()\n","  x = train_x[0:5,:]\n","  y = train_y[0:5]\n","  x,_,_ = normalize(x,x,x)\n","  y = create_one_hot(y,10)\n","\n","  for i in range(10):\n","    test_dict = softmax_test_case[\"output\"][i]\n","    classifier = SoftmaxClassifier((x.shape[1],10))\n","    classifier.w = test_dict[\"w\"]\n","\n","    y_hat = classifier.feed_forward(x)\n","    loss = classifier.compute_loss(y,y_hat)\n","    grad = classifier.get_grad(x,y,y_hat)\n","\n","    testcase_check(y_hat, test_dict['y_hat'], \"feed_forward / softmax\", True)\n","    testcase_check(loss, test_dict['loss'], \"compute_loss\", True)\n","    testcase_check(grad, test_dict['grad'], \"get_grad\", True)\n","\n","\n","# Load unit tests\n","logistic_test_case = load_npy(\"./Assignment1/logistic_unittest.npy\")[()]\n","softmax_test_case = load_npy(\"./Assignment1/softmax_unittest.npy\")[()]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7yzZpItjWqe4"},"source":["# Bài 1: Phân loại hai lớp dùng logistic regression"]},{"cell_type":"markdown","metadata":{"id":"ecv42PtbW2YX"},"source":["## Dữ liệu Vehicles"]},{"cell_type":"markdown","metadata":{"id":"3cPITStuW6wW"},"source":["Tập dữ liệu Vehicles là tập gồm có 2 lớp: xe hơi và xe máy, được gán nhãn lớp 0 (xe hơi) và 1 (xe máy). Ta có thể đọc tập dữ liệu này bằng hàm `get_vehicle_data()`:"]},{"cell_type":"code","metadata":{"id":"qwTC-jzcWiFS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9797f0d1-efad-4212-c470-42719d587504"},"source":["train_x, train_y, test_x, test_y = get_vehicle_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading vehicle data...\n","EOF Reached\n","Done reading\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oJOUX3RsXH6k"},"source":["Ở đây, `train_x` là một numpy tensor có kích thước `2400 × 64 × 64` (ý nghĩa: tập dữ liệu huấn luyện `train_x` có 2400 mẫu, mỗi mẫu là 1 ảnh có chiều cao (height) và rộng (width) bằng 64)."]},{"cell_type":"code","metadata":{"id":"ygeWwMeLXCVG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"694835d8-85ab-4a9e-b394-da5ba7c6b6cf"},"source":["train_x.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2400, 64, 64)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"sjePyisfXPES"},"source":["`train_y` là ma trận chứa nhãn ứng với mẫu dữ liệu trong `train_x`."]},{"cell_type":"code","metadata":{"id":"rkUDMyxrXOCZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"489b0415-40e5-4b06-ae68-cffec363c0db"},"source":["train_y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2400, 1)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Ain-QssjXl_6"},"source":["Tương tự, `test_x` có kích thước `600 × 64 × 64`, mỗi hàng trong `test_y` biểu diễn cho nhãn của mỗi mẫu trong `test_x`."]},{"cell_type":"code","metadata":{"id":"R_ceIkDBXWkp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09888109-c6c3-4d80-f44f-ac77df14c530"},"source":["print(test_x.shape)\n","print(test_y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(600, 64, 64)\n","(600, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o_rh0p9xYF5S"},"source":["Hai tensor `train_x` và `train_y` được dùng cho việc huấn luyện mô hình phân loại; hai tensor `test_x` và `test_y` được dùng cho quá trình đánh giá (test)."]},{"cell_type":"markdown","metadata":{"id":"03loyD0hYUrJ"},"source":["Tập dữ liệu này gồm các ảnh xám (gray images), mỗi ảnh chứa một trong hai loại phương tiện di chuyển: xe máy và xe hơi. Mỗi ảnh có thể chứa trọn vẹn hoặc một phần phương tiện. Cần lưu ý là dữ liệu ảnh ở đây chưa được chuẩn hóa, nên các giá trị vẫn nằm trong khoảng từ 0 đến 255."]},{"cell_type":"code","metadata":{"id":"GwY_Zi5VX7Hr","colab":{"base_uri":"https://localhost:8080/","height":268},"outputId":"082082b1-8bbb-4884-8579-4b219e432a8d"},"source":["imgplot = plt.imshow(train_x[0])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"FzGjMBfurRIQ","colab":{"base_uri":"https://localhost:8080/","height":268},"outputId":"5b7d6f05-4bd6-4dd4-f182-2ae2277aaf4e"},"source":["imgplot = plt.imshow(train_x[2399])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Rul5BLAlOMOC"},"source":["## Chuẩn hóa dữ liệu ảnh\n","Như đã kể trên, ảnh đầu vào có giá trị từ 0 đến 255. Nếu ta đưa trực tiếp bộ ảnh vào quá trình huấn luyện sẽ làm cho gradient lớn. Vì vậy, trước khi huấn luyện, ta có thể sử dụng phương pháp chuẩn hóa dữ liệu để đưa trung bình (mean) của tập train về 0 và độ lệch chuẩn (standard deviation - std) của nó về 1.\n","\n","Đối với việc xử lý hình ảnh, ta có hai cách chuẩn hóa khác nhau:\n","*   (a) Xem mỗi pixel trong ảnh là một đặc trưng riêng rẽ. Ví dụ, pixel [1, 3] và pixel [4, 2] là hai đặc trưng khác nhau, được tính mean và std riêng.\n","*   (b) Xem các pixel khác nhau trong ảnh là cùng 1 loại đặc trưng. Lúc này, pixel [1, 3] và pixel [4, 2] được xem là cùng 1 loại đặc trưng, được tính mean và std chung.\n","\n","Trong mục này, bạn cần hiện thực cách chuẩn hóa (a) trong hàm ```normalize_per_pixel``` và cách (b) trong hàm ```normalize_all_pixel```. Giả sử ta có ```m``` ảnh train ```x_0..xm−1```, mỗi ảnh train có R hàng và C cột, thì mean và std tính theo cách (a) sẽ là:\n","\n","\\begin{equation}\n","\\overline{x}_{rc}=\\frac{1}{m}\\sum_{i=0}^{m-1}x_{rc}^{(i)}, 0 \\le r \\le R-1,0 \\le c \\le C-1 \\tag{1}\n","\\end{equation}\n","\n","\\begin{equation}\n","\\sigma_{rc}=\\sqrt{\\frac{1}{m}\\sum_{i=0}^{m-1}{(x_{rc}^{(i)}-\\overline{x}_{rc})^2}} \\tag{2}\n","\\end{equation}\n","\n","Đối với cách (b) ta sẽ có:\n","\n","\\begin{equation}\n","\\overline{x} = \\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{x_{rc}^{(i)}}}} \\tag{3}\n","\\end{equation}\n","\n","\\begin{equation}\n","\\sigma=\\sqrt{\\frac{1}{mRC}\\sum_{i=0}^{m-1}{\\sum_{r=0}^{R-1}{\\sum_{c=0}^{C-1}{(x_{rc}^{(i)}-\\overline{x})^2}}}} \\tag{4}\n","\\end{equation}\n","\n","Sau khi có được mean và std trên toàn bộ data huấn luyện, ta chuẩn hóa các mẫu trong tập huấn luyện theo cách sau:\n","\n","\\begin{equation}\n","x^{(i)} = \\frac{x^{(i)}-\\overline{x}}{\\sigma} \\tag{5}\n","\\end{equation} \n","\n","Đối với cách (a), việc này sẽ được áp dụng riêng cho từng pixel trong số $R\\times{C}$. Với cách (b), thì ta dùng chung $\\overline{x}$ và $\\sigma$ trong công thức (3) và (4) cho toàn bộ tất cả các pixel.\n","\n","Cần lưu ý rằng $\\overline{x}$ và $\\sigma$ chỉ được tính trên $m$ mẫu dữ liệu huấn luyện. Sau đó, hai giá trị này sẽ được dùng lại để chuẩn hóa các mẫu dữ liệu test (và validation nếu có). Việc tính $\\overline{x}$ và $\\sigma$ mà có sử dụng các dữ liệu trong tập test là vi phạm nguyên tắc đánh giá các mô hình học máy. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"bzRsJ5bWoGt9"},"source":["#### TODO 1: normalize_per_pixel "]},{"cell_type":"code","metadata":{"id":"NB53DTTQmqCA"},"source":["# GRADED FUNCTION: normalize_per_pixel\n","def normalize_per_pixel(train_x, test_x):\n","    \"\"\"TODO 1: normalize_per_pixel\n","    This function computes the mean and standard deviation of the pixels located at the same coordinates across and training images\n","    and performs data scaling on train_x and test_x using these computed values.\n","\n","    :param train_x: training images, shape=(num_train, image_height, image_width)\n","    :param test_x: test images, shape=(num_test, image_height, image_width)\n","    \"\"\"\n","    # The shape of train_mean and train_std should be (1, image_height, image_width)\n","    ### START CODE HERE ### (≈4 lines)\n","\n","    \n","    ### END CODE HERE ###\n","    \n","    return train_x, test_x\n","\n","# Unit test\n","test_data = train_x[0:5,:,:]\n","test_data_norm, _ = normalize_per_pixel(test_data,test_data)\n","testcase_check(test_data_norm,logistic_test_case[\"train_x_norm1\"],\"normalize_per_pixel\",True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSU-sZg3oM7N"},"source":["#### TODO 2: normalize_all_pixel"]},{"cell_type":"code","metadata":{"id":"yguGEWe1msRo"},"source":["# GRADED FUNCTION: normalize_per_pixel\n","def normalize_all_pixels(train_x, test_x):\n","    \"\"\"TODO 2: normalize_all_pixels\n","    This function computes the mean and standard deviation of all pixels and performs data scaling on train_x and test_x using these computed values.\n","\n","    :param train_x: training images, shape=(num_train, image_height, image_width)\n","    :param test_x: test images, shape=(num_test, image_height, image_width)\n","    \"\"\"\n","    # The shape of train_mean and train_std should be (1, 1, 1).\n","    ### START CODE HERE ### (≈4 lines)\n","    \n","    \n","    ### END CODE HERE ###\n","    \n","    return train_x, test_x\n","\n","# Unit test\n","test_data = train_x[0:5,:,:]\n","test_data_norm, _ = normalize_all_pixels(test_data,test_data)\n","testcase_check(test_data_norm,logistic_test_case[\"train_x_norm2\"],\"normalize_all_pixel\",True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-nakFutobwo"},"source":["## Duỗi dữ liệu\n","\n","Dữ liệu ở bước trên vẫn còn ở dạng tensor 3D ($2400 \\times 64 \\times 64$). Để có thể thực hiện các phép nhân ma trận trong bài toán logistic regression, ta cần chuẩn chúng về dạng tensor 2D ($2400 \\times 4096$). Các bạn cần thực hiện bước này trong hàm `reshape2D`."]},{"cell_type":"markdown","metadata":{"id":"fZP6cBp5osT5"},"source":["#### TODO 3: reshape2D"]},{"cell_type":"code","metadata":{"id":"EWQ-uSJdtMzK"},"source":["# GRADED FUNCTION: reshape2D\n","def reshape2D(tensor):\n","    \"\"\"TODO 3: reshape_2D\n","    Reshape our 3D tensors to 2D. A 3D tensor of shape (num_samples, image_height, image_width) must be reshaped into (num_samples, image_height*image_width).\n","    \"\"\"\n","    result = None\n","    ### START CODE HERE ### (≈1 line)\n","    \n","    ### END CODE HERE ###\n","    return result\n","\n","# Unit test\n","test_data = logistic_test_case[\"train_x_norm2\"]\n","reshaped_test_data = reshape2D(test_data)\n","testcase_check(reshaped_test_data,logistic_test_case[\"train_x2D\"],\"reshape2D\",True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LRCYuQCfpl1T"},"source":["## Thêm đặc trưng 1 vào dữ liệu\n","Để tính tích vô hướng dễ dàng, nối thêm một cột có giá trị bằng 1 vào `train_x` và `test_x` (concatenate có axis=1). Trong file có sẵn hàm `add_one` và ta nên thực hiện code trong hàm này. Sau bước này, dữ liệu huấn luyện sẽ có kích thước $2400 \\times 4097$."]},{"cell_type":"markdown","metadata":{"id":"GwSNZlg2qFCv"},"source":["#### TODO 4: add_one"]},{"cell_type":"code","metadata":{"id":"0d732mHkqDWn"},"source":["# GRADED FUNCTION: add_one\n","def add_one(x):\n","    \"\"\"TODO 4: add_one\n","    This function add ones as an additional feature for x.\n","\n","    :param x: input data\n","    \"\"\"\n","    ### START CODE HERE ### (≈1 line)\n","    \n","    ### END CODE HERE ###\n","    return x\n","\n","# Unit test\n","test_data = logistic_test_case[\"train_x2D\"]\n","added_test_data = add_one(test_data)\n","testcase_check(added_test_data,logistic_test_case[\"train_x1\"],\"add_one\",True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5bgGyuw7rJWg"},"source":["## Class LogisticClassifier\n","\n","Nhằm hỗ trợ cho việc lập trình, đội ngũ TA cung cấp sẵn cho các bạn class **LogisticClassifier**. Một trong các thành phần chính của class LogisticClassifier là `w`, tham số mà ta cần tìm khi huấn luyện. Tham số này là một mảng có số hàng bằng số đặc trưng của dữ liệu đầu vào, số cột bằng 1. Cụ thể trong bài toán phân loại ảnh xe này, `w` sẽ là một ma trận $4097\\times{1}$. `w` được khởi tạo ngẫu nhiên trong hàm `__init__(w_shape)`. Để truy xuất `w` từ bên trong class, ta dùng `self.w`, ví dụ:\n","```python\n","class logistic_classifier(object):\n","    def feed_forward(self, x):\n","        print(self.w)\n","```"]},{"cell_type":"markdown","metadata":{"id":"bvCZwnjktV88"},"source":["Để truy xuất w từ bên ngoài class, ta cần có một thực thể của class và gọi thông qua thực thể này, ví dụ:\n","```python\n","if __name__ == \"__main__\":\n","    num_feature = train_x.shape[1]\n","    bin_classifier = LogisticClassifier((num_feature, 1))\n","    print(bin_classifier.w)\n","```"]},{"cell_type":"markdown","metadata":{"id":"EDSIBJPatljC"},"source":["Đối với các hàm thuộc class **LogisticClassifier**, việc truy xuất cũng hoàn toàn giống với `w`. Chúng sẽ được mô tả chi tiết trong mục tiếp theo."]},{"cell_type":"code","metadata":{"id":"-HvKyAwnteLa"},"source":["# GRADED FUNCTION\n","class LogisticClassifier(object):\n","    def __init__(self, w_shape):\n","        \"\"\"__init__\n","        \n","        :param w_shape: create w with shape w_shape using normal distribution\n","        \"\"\"\n","\n","        mean = 0\n","        std = 1\n","        self.w = np.random.normal(0, np.sqrt(2./np.sum(w_shape)), w_shape)\n","\n","\n","    def feed_forward(self, x):\n","        \"\"\"TODO 5: feed_forward\n","        This function computes the output of your logistic classification model.\n","        \n","        :param x: input\n","        \"\"\"\n","        result = None\n","        \n","        ### START CODE HERE ### (≈2 lines)\n","      \n","        ### END CODE HERE ###\n","        \n","        return result\n","\n","\n","    def compute_loss(self, y, y_hat):\n","        \"\"\"TODO 6: compute_loss\n","        Compute the loss using y (label) and y_hat (predicted class).\n","\n","        :param y:  the label, the actual class of the sample\n","        :param y_hat: the probabilities that the given sample belong to class 1\n","        \"\"\"\n","        loss = 0\n","        \n","        ### START CODE HERE ### (≈2 lines)\n","\n","        ### END CODE HERE ###\n","        \n","        return loss\n","\n","\n","    def get_grad(self, x, y, y_hat):\n","        \"\"\"TODO 7: get_grad\n","        Compute and return the gradient of w.\n","\n","        :param x: input\n","        :param y: the label, the actual class of the sample data\n","        :param y_hat: predicted y\n","        \"\"\" \n","        w_grad = None\n","        \n","        ### START CODE HERE ### (≈2 lines)\n","\n","        ### END CODE HERE ###\n","        \n","        return w_grad\n","\n","\n","    def update_weight(self, grad, learning_rate):\n","        \"\"\"TODO 8: update_weight\n","        Update w using the computed gradient.\n","\n","        :param grad: gradient computed from the loss\n","        :param learning_rate: float, learning rate\n","        \"\"\"\n","        ### START CODE HERE ### (≈1 line)\n","\n","        ### END CODE HERE ###\n","        return self.w\n","\n","\n","    def update_weight_momentum(self, grad, learning_rate, momentum, momentum_rate):\n","        \"\"\"TODO 9: update_weight using momentum\n","        BONUS:[YC1.8]\n","        Update w using the algorithm with momentum\n","\n","        :param grad: gradient computed from the loss\n","        :param learning_rate: float, learning rate\n","        :param momentum: the array storing momentum for training w, should have the same shape as that of w\n","        :param momentum_rate: float, how much momentum to reuse after each loop (denoted as gamma in the following section)\n","        \"\"\"\n","        ### START CODE HERE ### (≈3 lines)\n","\n","        ### END CODE HERE ###\n","        return self.w\n","\n","\n","    def numerical_check(self, x, y, grad):\n","        eps = 0.000005\n","        w_test0 = np.copy(self.w)\n","        w_test1 = np.copy(self.w)\n","        w_test0[2] = w_test0[2] - eps\n","        w_test1[2] = w_test1[2] + eps\n","\n","        y_hat0 = np.dot(x, w_test0)\n","        y_hat0 = 1. / (1. + np.exp(-y_hat0))\n","        loss0 = self.compute_loss(y, y_hat0) \n","\n","        y_hat1 = np.dot(x, w_test1)\n","        y_hat1 = 1. / (1. + np.exp(-y_hat1))\n","        loss1 = self.compute_loss(y, y_hat1) \n","\n","        numerical_grad = (loss1 - loss0)/(2*eps)\n","        print(numerical_grad)\n","        print(grad[2])\n","\n","# Unit test\n","logistic_unit_test()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hPll6bewuoqH"},"source":["## Tính các giá trị phân loại\n","\n","Các giá trị phân loại, $\\hat{y}$, sẽ được tính trong hàm `feed_forward` của class `LogisticClassifier`. Công thức tính như sau:\n","\n","\\begin{equation}\n","z = xw  \\tag{6}\n","\\end{equation}\n","\\begin{equation}\n","\\hat{y} = \\frac{1}{1+e^{-z}} \\tag{7}\n","\\end{equation}\n","\n","Ở đây, $w = [w_0, w_1,.., w_{4096}]^T$ là các tham số cần học (lưu trong biến `self.w` trong class `LogisticClassifier`). Lẽ ra công thức (6) được viết là $z=xw+w_{4096}$, tuy nhiên ở bước trên ta đã thêm 1 vào làm đặc trưng cuối cho tất cả các mẫu. Việc này giúp cho quá trình nhân ma trận và quản lý các biến gọn hơn."]},{"cell_type":"markdown","metadata":{"id":"BODXyv9Hu8gm"},"source":["#### TODO 5: feed_forward\n","\n","Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=-HvKyAwnteLa)."]},{"cell_type":"markdown","metadata":{"id":"QhgYv_vEyNI2"},"source":["## Tính độ lỗi\n","\n","Việc tính độ lỗi được thực hiện trong hàm `compute_loss` của class `LogisticClassifier`. Công thức tính độ lỗi như sau:\n","\n","\\begin{equation}\n","J(w) = -\\frac{1}{m}\\sum_{i=0}^{m-1}(y^{(i)}\\log{\\hat{y}^{(i)}} + (1-y^{(i)})\\log(1-\\hat{y}^{(i)})) \\tag{8}\n","\\end{equation}\n","\n","Trong đó:\n","-  $y^{(i)}$ là nhãn của mẫu thứ $i$, mẫu thuộc lớp 0 sẽ có $y^{(i)}=0$, mẫu thuộc lớp 1 sẽ có $y^{(i)}=1$. Ta có thể truy cập các nhãn này thông qua biến `train_y` và `test_y`.\n","- $\\hat{y}^{(i)} \\in (0, 1)$ là phần tử thứ $i$ trong vector $\\hat{y}$.\n","- $m=2400$ là tổng số mẫu huấn luyện.\n","\n","\n","Để tính trung bình trên ma trận theo hàng hoặc cột, ta có thể sử dụng hàm `np.mean()` với tham số axis tương ứng."]},{"cell_type":"markdown","metadata":{"id":"fobSVpxdzJCK"},"source":["#### TODO 6: compute_loss\n","\n","Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=-HvKyAwnteLa)."]},{"cell_type":"markdown","metadata":{"id":"akV674wBzsi6"},"source":["## Tính đạo hàm\n","Để tính đạo hàm riêng cho thành phần $w_j$ trong $w$ trong hàm `get_grad`, ta dùng công thức sau:\n","\\begin{equation}\n","\\frac{\\partial  J(w_j)}{\\partial w_j} = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{y}^{(i)} - y^{(i)})x^{(i)}_j \\tag{9}\n","\\end{equation}\n","\n","Trong trường hợp này, sau khi thêm 1 vào `train_x` thì ta sẽ có $0 \\le j \\le 4096$."]},{"cell_type":"markdown","metadata":{"id":"PpjrfpjT0W85"},"source":["#### TODO 7: get_grad\n","Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=-HvKyAwnteLa)."]},{"cell_type":"markdown","metadata":{"id":"Sh9WycsLLocE"},"source":["## Cập nhật $w$\n","Để huấn luyện được mô hình phân loại trong hàm `update_weight`, ta cần cập nhật $w$ theo công thức sau:\n","\\begin{equation}\n","w = w - \\alpha\\times\\frac{\\partial  J(w)}{\\partial w} \\tag{10}\n","\\end{equation}\n","\n","Với $\\alpha$ là hệ số học (`learning_rate`)."]},{"cell_type":"markdown","metadata":{"id":"GpHPICzyL7eW"},"source":["#### TODO 8: update_weight\n","Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=-HvKyAwnteLa)."]},{"cell_type":"markdown","metadata":{"id":"8KLXKJ_IM301"},"source":["## Cập nhật $w$ dùng momentum\n","\n","Giải thuật cập nhật trình bày trong phần trước có điểm yếu là chậm và dễ rơi vào tối ưu cục bộ. Tuy trong bài này, giải thuật đó cũng đủ để giải quyết, nhưng ta vẫn có thể sử dụng giải thuật có quán tính để việc huấn luyện diễn ra nhanh hơn.\n","\n","Khởi tạo ma trận quán tính trước khi vào vòng lặp chính:\n","\\begin{equation}\n","\\Delta w = 0 \\tag{11}\n","\\end{equation}\n","\n","Ở đây, $\\Delta w$ là ma trận có kích thước bằng chính kích thước của $w$. Quá trình cập nhật $w$ sẽ được diễn ra như sau:\n","\\begin{equation}\n","\\Delta w = \\gamma\\Delta w + \\alpha\\frac{\\partial  J(w)}{\\partial w} \\tag{12}\n","\\end{equation}\n","\n","\\begin{equation}\n","w = w - \\Delta w \\tag{13}\n","\\end{equation}\n","\n","Với $\\gamma$ là hệ số quán tính (thường được đặt là 0.9)."]},{"cell_type":"markdown","metadata":{"id":"ZmqEjanxNUt_"},"source":["#### TODO 9: update_weight_momentum\n","\n","Các bạn làm bài vào phần class [ở trên](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=-HvKyAwnteLa)."]},{"cell_type":"markdown","metadata":{"id":"wrP0xiO8NvzD"},"source":["## Đánh giá mô hình phân loại\n","Để đánh giá mô hình phân loại trên tập kiểm thử (`test_x` và `test_y`), trước tiên, ta cần thực hiện tính các giá trị phân loại trên`test_x`. Sau khi đã có các giá trị này, ta sử dụng các tiêu chí sau để đánh giá mô hình:\n","\n","\\begin{equation}\n","Precision = \\frac{TP}{TP+FP} \\tag{14}\n","\\end{equation}\n","\n","\\begin{equation}\n","Recall = \\frac{TP}{P} \\tag{15}\n","\\end{equation}\n","\n","\\begin{equation}\n","F_1-score = 2\\times\\frac{Precision\\times Recall}{Precision+Recall} \\tag{16}\n","\\end{equation}\n","\n","Trong đó:\n","- Lớp positive là lớp có giá trị y = 1.\n","- TP (true positive) là tổng số các mẫu mà mô hình dự đoán là positive. ($\\hat{y}=1$) và thực sự có nhãn là positive ($y=1$).\n","- FP (false positive) là tổng số các mẫu mô hình dự đoán là positive($\\hat{y}=1$) nhưng thực chất có nhãn là negative ($y=0$).\n","- P là tổng số mẫu positive trong tập test.\n","\n","Nhiệm vụ của bạn trong bước này là tính các thông số trên trong hàm `test`. Khi tiến hành kiểm thử, người ra đề đã tính được các giá trị $Precision=0.766$, $Recall=0.830$ và $F_1-score=0.797$. Bạn hãy cố gắng hoàn thiện bài làm của mình để đạt kết quả tương tự hoặc tốt hơn."]},{"cell_type":"markdown","metadata":{"id":"jz8g3el2Ork0"},"source":["#### TODO 10: test"]},{"cell_type":"code","metadata":{"id":"8dYywqX6tOS9"},"source":["# GRADED FUNCTION\n","def test(y_hat, test_y, thres=0.5):\n","    \"\"\"TODO 10: test\n","    Compute precision, recall and F1-score based on predicted test values\n","\n","    :param y_hat: predicted values, output of classifier.feed_forward\n","    :param test_y: test labels\n","    \"\"\"\n","    \n","    # Compute test scores using test_y and y_hat\n","\n","    precision = 0\n","    recall = 0\n","    f1 = 0\n","    ### START CODE HERE ### (≈7 lines)\n","\n","    ### END CODE HERE ###\n","\n","    return precision, recall, f1\n","\n","### SANITY CHECK\n","y_hat = np.array([0.4, 0.7, 0.8, 0.3, 0.2])\n","test_y = np.array([0, 1, 1, 0, 0])\n","assert sum(test(y_hat, test_y)) == 3, \"Wrong\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4e3JORB8PEfL"},"source":["## Vòng lặp huấn luyện\n","\n","Vòng lặp của quá trình huấn luyện được xây dựng trong đoạn code sau đây. Tất cả khung sườn cho việc thực thi đã được lập trình sẵn. Ta có thể thay đổi hai tham số tác động đến quá trình huấn luyện như sau:\n","\n","- `num_epoch`: số lượng vòng lặp cho quá trình huấn luyện.\n","- `learning_rate`: hệ số học $\\alpha$.\n","- `momentum_rate`: hệ số momentum $\\gamma$.\n","- `epochs_to_draw`: số lượng epochs cần đạt được để vẽ đồ thị độ lỗi trong lúc huấn luyện."]},{"cell_type":"code","metadata":{"id":"HEoEEijecqXi"},"source":["def plot_loss(all_loss):\n","    plt.figure(1)\n","    plt.clf()\n","    plt.plot(all_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkrzCU6lPak7"},"source":["#@title Training { display-mode: \"both\" }\n","normalize_method = \"per_pixel\" #@param [\"all_pixels\", \"per_pixel\"]\n","update_weight_method = \"normal\" #@param [\"normal\", \"momentum\"]\n","num_epoch = 1000 #@param {type:\"integer\"}\n","learning_rate = 0.01 #@param {type:\"number\"}\n","momentum_rate = 0.9 #@param {type:\"number\"}\n","epochs_to_draw = 100 #@param {type:\"integer\"}\n","\n","np.random.seed(2020)\n","\n","# Load data from file\n","# Make sure that vehicles.dat is in data/\n","train_x, train_y, test_x, test_y = get_vehicle_data()\n","num_train = train_x.shape[0]\n","num_test = test_x.shape[0]\n","\n","# Normalize our data: choose one of the two methods before training\n","if normalize_method == \"all_pixels\":\n","    train_x, test_x = normalize_all_pixels(train_x, test_x) \n","else:\n","    train_x, test_x = normalize_per_pixel(train_x, test_x) \n","\n","# Reshape our data\n","# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n","# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n","train_x = reshape2D(train_x)\n","test_x = reshape2D(test_x)\n","\n","# Pad 1 as the last feature of train_x and test_x\n","train_x = add_one(train_x) \n","test_x = add_one(test_x)\n","\n","# Create classifier\n","num_feature = train_x.shape[1]\n","bin_classifier = LogisticClassifier((num_feature, 1))\n","momentum = np.zeros_like(bin_classifier.w)\n","\n","# Define hyper-parameters and train-related parameters\n","all_loss = []\n","plt.ion()\n","for e in range(num_epoch):    \n","    y_hat = bin_classifier.feed_forward(train_x)\n","    loss = bin_classifier.compute_loss(train_y, y_hat)\n","    grad = bin_classifier.get_grad(train_x, train_y, y_hat)\n","\n","    # Updating weight: choose either normal SGD or SGD with momentum\n","    if update_weight_method == \"normal\":\n","        bin_classifier.update_weight(grad, learning_rate)\n","    else: \n","        bin_classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n","\n","    all_loss.append(loss) \n","\n","    if (e % epochs_to_draw == epochs_to_draw-1):\n","        plot_loss(all_loss)\n","        plt.show()\n","        plt.pause(0.1)     \n","        print(\"Epoch %d: loss is %.5f\" % (e+1, loss))\n","\n","y_hat = bin_classifier.feed_forward(test_x)\n","precision, recall, f1 = test(y_hat, test_y)\n","print(\"Precision: %.3f\" % precision)\n","print(\"Recall: %.3f\" % recall)\n","print(\"F1-score: %.3f\" % f1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ZvVpS7iPvVr"},"source":["**Sau khi hoàn thành bài tập trên với numpy, các bạn tiến hành cài đặt lại với tensorflow. **"]},{"cell_type":"markdown","metadata":{"id":"FZmlnIx6QlPu"},"source":["## Định Nghĩa Lớp LogisticRegressionTF"]},{"cell_type":"markdown","metadata":{"id":"pVi-LxozARSO"},"source":["Chúng ta sử dụng tensorflow eager execution để cài đặt mô hình logistic regression. Với tf eager execution, giá trị của các biến được tính toán ngay lập tức thay vì xây dựng computational graph để chạy sau đó. Một trong những lợi ích thiết thực nhất là giúp chúng ta dễ dàng debug mô hình, xây dựng được dynamic model.\n","\n","Để xây dựng mô hình bằng eager execution, chúng ta thường định nghĩa một lớp đối tượng như mình họa ở dưới.\n","\n","Chúng ta kế thừa lớp Model và cài đặt 2 hàm chính:\n","- init: khởi tạo tất cả các tham số. \n","- call: hàm dùng cho feedforward."]},{"cell_type":"code","metadata":{"id":"s5BdlvtmE6Li"},"source":["class LogisticRegressionTF(tf.keras.Model):\n","\n","    def __init__(self, num_class):\n","        super(LogisticRegressionTF, self).__init__()\n","        # init all weights here\n","        self.dense = tf.keras.layers.Dense(num_class)\n","\n","    def call(self, inputs, training=None, mask=None):\n","        output = self.dense(inputs)\n","        output = tf.nn.softmax(output)        \n","        return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4s4l4aqreJX"},"source":["#### TODO 11: Định nghĩa one hot encoder"]},{"cell_type":"code","metadata":{"id":"HQu3SvkzrdkK"},"source":["# GRADED FUNCTION: create_one_hot\n","def create_one_hot(labels, num_k=10):\n","    \"\"\"TODO 11: create_one_hot\n","    This function creates a one-hot (one-of-k) matrix based on the given labels.\n","\n","    :param labels: list of labels, each label is one of 0, 1, 2,... , num_k - 1\n","    :param num_k: number of classes we want to classify\n","    \"\"\"\n","    eye_mat = None\n","    ### START CODE HERE ### (≈2 lines)\n","\n","    ### END CODE HERE ###\n","    return eye_mat\n","\n","# Unit test\n","x = [1, 2, 3]\n","y = create_one_hot(x, 4)\n","assert y.shape == (3,4), \"Wrong\"\n","assert sum(np.argmax(y, axis=0)) == 3, \"Wrong\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1qTPLe3RZERS"},"source":["### Huấn luyện mô hình với tensorflow"]},{"cell_type":"code","metadata":{"id":"D4bYf9IBZJHY"},"source":["#@title Training { display-mode: \"both\" }\n","normalize_method = \"all_pixels\" #@param [\"all_pixels\", \"per_pixel\"]\n","num_epoch = 14 #@param {type:\"integer\"}\n","learning_rate = 0.001 #@param {type:\"number\"}\n","batch_size = 32\n","num_classes = 2\n","np.random.seed(2020)\n","tf.random.set_seed(2020)\n","\n","# Load data from file\n","# Make sure that vehicles.dat is in data/\n","train_x, train_y, test_x, test_y = get_vehicle_data()\n","num_train = train_x.shape[0]\n","num_test = test_x.shape[0]  \n","\n","#generate_unit_testcase(train_x.copy(), train_y.copy()) \n","#logistic_unit_test()\n","\n","# Normalize our data: choose one of the two methods before training\n","if normalize_method == \"all_pixels\":\n","    train_x, test_x = normalize_all_pixels(train_x, test_x) \n","else:\n","    train_x, test_x = normalize_per_pixel(train_x, test_x) \n","\n","# Reshape our data\n","# train_x: shape=(2400, 64, 64) -> shape=(2400, 64*64)\n","# test_x: shape=(600, 64, 64) -> shape=(600, 64*64)\n","train_x = reshape2D(train_x)\n","test_x = reshape2D(test_x)\n","train_y = create_one_hot(train_y.astype('int32').flatten().tolist(), num_k=2)\n","test_y = create_one_hot(test_y.astype('int32').flatten().tolist(), num_k=2)\n","\n","device = '/cpu:0' if len(tf.config.experimental.list_physical_devices('GPU')) == 0 else '/gpu:0'\n","\n","with tf.device(device):\n","    # build model and optimizer\n","    model = LogisticRegressionTF(num_classes)\n","    model.compile(optimizer=tf.optimizers.Adam(learning_rate), loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    \n","\n","    # train\n","    model.fit(train_x, train_y, batch_size=batch_size, epochs=num_epoch,\n","              validation_data=(test_x, test_y), verbose=2)\n","\n","    # evaluate on test set\n","    scores = model.evaluate(test_x, test_y, 32, verbose=2)\n","    \n","    y_hat = model.predict(test_x)\n","    precision, recall, f1 = test(y_hat, test_y)\n","    print(\"Precision: %.3f\" % precision)\n","    print(\"Recall: %.3f\" % recall)\n","    print(\"F1-score: %.3f\" % f1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9U9Se7dsfv9P"},"source":["# Bài 2: Phân loại mười lớp"]},{"cell_type":"markdown","metadata":{"id":"cLYyjVEzf-6A"},"source":["## Dữ liệu fashion MNIST\n","\n","Ta có thể đọc tập dữ liệu này bằng hàm `get_mnist_data()`:"]},{"cell_type":"code","metadata":{"id":"jOMEH7P8enH1"},"source":["train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23aegpJ3gOVJ"},"source":["Tập dữ liệu này gồm các ảnh xám kích thước $28 \\times 28$. Có tất cả 50000 ảnh train, 10000 ảnh validation và 10000 ảnh test. Mỗi ảnh thuộc một trong 10 loại quần, áo, giày, túi xách, v.v. Tuy nhiên trong bài tập này ta chỉ lấy 2500 ảnh train, 500 ảnh validation và 500 ảnh test.\n"]},{"cell_type":"code","metadata":{"id":"F1pvh-JTgK2q"},"source":["print(train_x.shape)\n","print(train_y.shape)\n","print(val_x.shape)\n","print(val_y.shape)\n","print(test_x.shape)\n","print(test_y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mE7g9Yt4gxDB"},"source":["imgplot = plt.imshow(train_x[0].reshape(28,28))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKyk9vYKhLik"},"source":["imgplot = plt.imshow(train_x[100].reshape(28,28))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eRUHcjC2hkEv"},"source":["Lưu ý là giá trị của `train_y` và `test_y` sẽ có thể là 0, 1, ..., 9 thay vì 0 và 1 như bài 1. Ngoài ra, dữ liệu này khi được đọc lên đã có dạng tensor 2D ($3500 \\times 784$)."]},{"cell_type":"markdown","metadata":{"id":"9fRHnz3FizC0"},"source":["## Chuẩn hóa dữ liệu\n","Trong bước này, ta sẽ chuẩn hóa dữ liệu `train_x`, `val_x` và `test_x` theo cách (b) đã đề cập trong phần trước. Tuy nhiên, do tập dữ liệu MNIST khi load đã được đặt dưới dạng tensor 2D, nên trong công thức tính tổng chỉ còn $m$ và $R=784$."]},{"cell_type":"markdown","metadata":{"id":"IGDUBrGmjand"},"source":["#### TODO 12: normalize"]},{"cell_type":"code","metadata":{"id":"BfgkYMdLivKW"},"source":["# GRADED FUNCTION: normalize\n","def normalize(train_x, val_x, test_x):\n","    \"\"\"TODO 12: normalize\n","    This function computes the mean and standard deviation of all pixels and performs data scaling on train_x, val_x and test_x using these computed values.\n","    Note that in this classification problem, the shape of the data is (num_samples, image_width * image_height).\n","\n","    :param train_x: train images, shape=(num_train, image_height * image_width)\n","    :param val_x: validation images, shape=(num_val, image_height * image_width)\n","    :param test_x: test images, shape=(num_test, image_height * image_width)\n","    \"\"\"\n","    # The shape of train_mean and train_std should be (1, 1)\n","    ### START CODE HERE ### (≈5 lines)\n","\n","    ### END CODE HERE ###\n","    return train_x, val_x, test_x\n","\n","# Unit test\n","x = train_x[0:5,:]\n","y = train_y[0:5]\n","x, _, _ = normalize(x,x,x)\n","testcase_check(x,softmax_test_case[\"train_x_norm\"],\"normalize\",True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RlidH1M6jjOe"},"source":["## Tiền xử lý vector label thành dạng one-hot\n","\n","Các biến `train_y`, `val_y`, `test_y` lúc này là một vector chứa các giá trị 0, 1, ..., 9; nhưng để tính hàm lỗi của softmax regression, ta nên chuyển chúng về dạng ma trận one-hot (one-of-k). Giả sử ta có vector label có 6 phần tử, mỗi phần tử nằm trong khoảng từ 0 đến 4:\n","\n","\\begin{equation}\n","\ty = [3,4,0,0,2,1]^T \\tag{17}\n","\\end{equation}\n","\n","Ta sẽ có biến đổi one-hot tương ứng của nó là:\n","\\begin{equation}\n","y = \\begin{bmatrix}\n","\t0 & 0 & 0 & \\color{red}1 & 0\\\\\n","\t0 & 0 & 0 & 0 & \\color{red}1\\\\\n","\t\\color{red}1 & 0 & 0 & 0 & 0\\\\\n","\t\\color{red}1 & 0 & 0 & 0 & 0\\\\\n","\t0 & 0 & \\color{red}1 & 0 & 0\\\\\n","\t0 & \\color{red}1 & 0 & 0 & 0\n","\\end{bmatrix} \\tag{18}\n","\\end{equation}\n","\n","Label thứ nhất có giá trị là 3, vì vậy nên trong hàng thứ nhất ở ma trận trên cột 3 có giá trị 1, tất cả các cột khác trong hàng này là 0. Tương tự cho hàng thứ 2, label là 4, nên cột 4 trong hàng 2 có giá trị là 1.\n","\n","\n","Để việc biến đổi giá trị của mảng sang dạng one-hot được nhanh chóng, ta nên sử dụng index array hay index vector trên ma trận đơn vị. Tham khảo thêm ở đây: [Numpy basic indexing - Index arrays](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html#index-arrays)."]},{"cell_type":"markdown","metadata":{"id":"1_9FgB3Jh8iV"},"source":["## Class SoftmaxClassifier\n","\n","Class này thừa kế lại một số thuộc tính từ class LogisticClassifier như `__init__`, `w`. Riêng với các hàm `feed_forward`, `compute_loss` và `get_grad` ta cần phải hiện thực lại. Hãy thực hiện và chạy thành công TODO 12 trước khi làm các TODO 13-16."]},{"cell_type":"code","metadata":{"id":"jKsh9eo5hOMq"},"source":["# GRADED FUNCTION\n","class SoftmaxClassifier(LogisticClassifier):\n","    def __init__(self, w_shape):\n","        \"\"\"__init__\n","        \n","        :param w_shape: create w with shape w_shape using normal distribution\n","        \"\"\"\n","        super(SoftmaxClassifier, self).__init__(w_shape)\n","\n","\n","    def softmax(self, x):\n","        \"\"\"TODO 14: softmax\n","\n","        :param x: input\n","        \"\"\"\n","        result = None\n","        ### START CODE HERE ### (≈4 lines)\n","\n","        ### END CODE HERE ###\n","        return result\n","\n","\n","    def feed_forward(self, x):\n","        \"\"\"TODO 13: feed_forward\n","        This function computes the output of your softmax regression model\n","        \n","        :param x: input\n","        \"\"\"\n","        result = None\n","        ### START CODE HERE ### (≈2 lines)\n","\n","        ### END CODE HERE ###\n","        return result\n","\n","\n","    def compute_loss(self, y, y_hat):\n","        \"\"\"TODO 15: compute_loss\n","        Compute the loss using y (label) and y_hat (predicted class)\n","\n","        :param y:  the label, the actual class of the sample data\n","        :param y_hat: the classifying probabilities of all sample data\n","        \"\"\"\n","        loss = 0\n","        ### START CODE HERE ### (≈3 lines)\n","\n","        ### END CODE HERE ###\n","        return loss\n","\n","\n","    def get_grad(self, x, y, y_hat):\n","        \"\"\"TODO 16: get_grad\n","        Compute and return the gradient of w\n","\n","        :param loss: computed loss between y_hat and y in the train dataset\n","        :param y_hat: predicted y\n","        \"\"\" \n","        w_grad = None\n","        ### START CODE HERE ### (≈2 lines)\n","\n","        ### END CODE HERE ###\n","        return w_grad\n","   \n","\n","    def numerical_check(self, x, y, grad):\n","        i = 3\n","        j = 0\n","        eps = 0.000005\n","        w_test0 = np.copy(self.w)\n","        w_test1 = np.copy(self.w)\n","        w_test0[i,j] = w_test0[i,j] - eps\n","        w_test1[i,j] = w_test1[i,j] + eps\n","\n","        y_hat0 = np.dot(x, w_test0)\n","        y_hat0 = self.softmax(y_hat0)\n","        loss0 = self.compute_loss(y, y_hat0) \n","\n","        y_hat1 = np.dot(x, w_test1)\n","        y_hat1 = self.softmax(y_hat1)\n","        loss1 = self.compute_loss(y, y_hat1) \n","\n","        numerical_grad = (loss1 - loss0)/(2*eps)\n","        print(numerical_grad)\n","        print(grad[i,j])\n","        \n","# Unit test\n","softmax_unit_test()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fGlHfM_lkgVT"},"source":["## Tính các giá trị phân loại\n","\n","Để tính các giá trị phân loại trong bài này, ta hiện thực các công thức sau trong hàm `feed_forward` và `softmax`:\n","\n","\\begin{equation}\n","z = xw \\space, \\quad x \\in R^{m\\times D}, w \\in R^{D \\times K} \\tag{19}\n","\\end{equation}\n","\n","Trong đó, $m$ là số lượng mẫu dữ liệu, $D$ là số lượng đặc trưng của dữ liệu đầu vào (785 sau khi thêm 1 vào cuối), $K$ là số lượng nhãn trong bài toán ta đang làm (10).\n","\n","\\begin{equation}\n","z_{max} = [max(z^{(0)}), max(z^{(1)}),.., max(z^{(m-1)})]^T  \\tag{20}\n","\\end{equation}\n","\n","Tại đây, $z_{max}$ là một vector cột (kích thước $m \\times 1$).\n","\n","\\begin{equation}\n","z' = e^{z - z_{max}} \\tag{21}\n","\\end{equation}\n","\n","Trong biểu thức trên, ta sẽ dùng cột thứ nhất của $z$ trừ cho $z_{max}$, cột thứ 2 của $z$ trừ cho $z_{max}$, v.v. Sau đó, ta tính lũy thừa cho từng phần tử trên hiệu đã tính. Kết quả tại bước này là một ma trận $z'$ có kích thước $m \\times K$.\n","\n","Kế tiếp, ta cần tính tổng sau:\n","\n","\\begin{equation}\n","s = \\sum^{K-1}_{k=0}z'^{(i)}_{k} ,\\quad 0\\le i \\le m-1\\tag{22}\n","\\end{equation}\n","\n","Như vậy, $s$ sẽ là vector chứa tổng từng hàng của ma trận $z'$. $s$ có kích thước $m \\times 1$. Sau cùng, ta có thể tính softmax bằng cách lấy mỗi phần tử trong $z'$ chia cho tổng hàng tương ứng:\n","\n","\\begin{equation}\n","\\hat{y}^{(i)}_{k} = \\frac{z'^{(i)}_{k}}{s^{(i)}}, \\quad 0\\le i \\le m-1, 0\\le k \\le K-1 \\tag{23}\n","\\end{equation}\n","\n","Sau khi tổng hợp lại toàn bộ các phần tử $i, k$ của $\\hat{y}$, ta sẽ có ma trận có kích thước $m \\times K$. Trong ma trận này, mỗi hàng thứ $i$ biểu diễn vector xác suất lớp của mẫu ảnh thứ $i$. Vì vậy, tổng của mỗi hàng luôn bằng 1."]},{"cell_type":"markdown","metadata":{"id":"Yy_5nMf7mOTW"},"source":["#### TODO 13: feed_forward\n","\n","Các bạn hoàn thành hàm `feed_forward` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=jKsh9eo5hOMq)."]},{"cell_type":"markdown","metadata":{"id":"2Oz_NZPmmp4V"},"source":["#### TODO 14: softmax\n","\n","Các bạn hoàn thành hàm `softmax` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=jKsh9eo5hOMq)."]},{"cell_type":"markdown","metadata":{"id":"8wm4-xOlnVMZ"},"source":["## Tính độ lỗi\n","Công thức tính độ lỗi category như sau:\n","\n","\\begin{equation}\n","J(w) = -\\frac{1}{m}\\sum_{i=0}^{m-1}\\sum_{k=0}^{K-1} y^{(i)}_k \\log\\hat{y}^{(i)}_k \\tag{24}\n","\\end{equation}\n","\n","Trong đó:\n","- $y^{(i)}_k$ là phần tử hàng $i$ cột $k$ trong ma trận nhãn one-hot $y$ (đã đề cập trong phần trước).\n","- $\\hat{y}^{(i)} \\in (0, 1)$ là hàng $i$ cột $k$ trong ma trận $\\hat{y}$."]},{"cell_type":"markdown","metadata":{"id":"SSvZIuG-oUwn"},"source":["#### TODO 15: compute_loss\n","Các bạn hoàn thành hàm `compute_loss` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=jKsh9eo5hOMq)."]},{"cell_type":"markdown","metadata":{"id":"x-NMfsp0o0Ja"},"source":["## Tính đạo hàm\n","Công thức tính đạo hàm theo từng tham số $w_{jk}$ được biểu diễn như sau:\n","\n","\\begin{equation}\n","\\frac{\\partial  J(w_{jk})}{\\partial w_{jk}} = \\frac{1}{m}\\sum_{i=0}^{m-1} x^{(i)}_j (\\hat{y}^{(i)}_k - y^{(i)}_k) \\tag{25}\n","\\end{equation}\n","\n","Với $0 \\le j \\le D-1$. Viết lại dưới dạng ma trận ta có được:\n","\n","\\begin{equation}\n","\\frac{\\partial  J(w)}{\\partial w} = \\frac{1}{m}x^T(\\hat{y} - y) \\tag{26}\n","\\end{equation}"]},{"cell_type":"markdown","metadata":{"id":"gHzTgKgeqLMM"},"source":["#### TODO 16: get_grad\n","Các bạn hoàn thành hàm `get_grad` ở phần class [SoftmaxClassifier](https://colab.research.google.com/drive/1Gostei1_ECf6itc4_YZBhtcoj_ee4Cdz?authuser=2#scrollTo=jKsh9eo5hOMq).\n"]},{"cell_type":"markdown","metadata":{"id":"bysiSaSEqiae"},"source":["## Đề xuất điều kiện dùng vòng lặp huấn luyện\n","\n","Trong bài này, ngoài việc sử dụng `train_x`, `train_y` để huấn luyện, file mẫu còn cung cấp cho các bạn các biến `val_x`, `val_y` để thực hiện validation. Toàn bộ các giá trị lỗi validation được lưu trong biến `all_val_loss`. Trong phần này, nhiệm vụ của các bạn là đề xuất ra điều kiện dừng khác (ngoài việc `e` đạt `num_epoch`) trong quá trình huấn luyện. Dựa vào độ lỗi validation, bạn có thể sử dụng các tiêu chí mình tự đề ra để tránh việc quá trình huấn luyện bị overfitting."]},{"cell_type":"markdown","metadata":{"id":"i1qjvU6MrE3G"},"source":["#### TODO 17: is_stop_training\n","\n","Các bạn hoàn thành hàm `is_stop_training`, hàm nhận vào mảng `all_val_loss` và trả về giá trị boolean True hoặc False quyết định có dừng việc huấn luyện lại hay không. Nếu loss trên tập validation tăng hơn n (>= n) lần liên tiếp thì trả về True, ngược lại là False."]},{"cell_type":"code","metadata":{"id":"_Xc5fXhhkfUC"},"source":["# GRADED FUNCTION: is_stop_training\n","def is_stop_training(all_val_loss, patience=5):\n","    \"\"\"TODO 17: is_stop_training\n","    Check whether training needs to be stopped\n","\n","    :param all_val_loss: list of all validation loss values during training\n","    \"\"\"\n","    is_stopped = False\n","    ### START CODE HERE ###\n","\n","    ### END CODE HERE ###\n","    return is_stopped\n","\n","# Unit test\n","assert is_stop_training([1, 2, 3, 4, 5, 6]) == True, \"Wrong\"\n","assert is_stop_training([1, 2, 3, 4, 5]) == False, \"Wrong\"\n","assert is_stop_training([1, 3, 2, 7, 4, 7, 7, 7, 7, 7, 7]) == False, \"Wrong\"\n","assert is_stop_training([1, 3, 2, 7, 4, 7, 8, 9, 11]) == False, \"Wrong\"\n","assert is_stop_training([1, 3, 2, 7, 4, 7, 8, 9, 11, 15]) == True, \"Wrong\"\n","assert is_stop_training([1, 2, 3]) == False, \"Wrong\"\n","#is_stop_training([1, 2, 3, 4, 5, 6, 8, 9, 11, 15])\n","#mảng loss trên không tồn tại vì model đã ngừng train khi loss = [1, 2, 3, 4, 5, 6]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaMfOmffvslM"},"source":["## Đánh giá mô hình trên dữ liệu test\n","\n","Để đánh giá mô hình phân loại nhiều lớp, ta cần sử dụng một khái niệm gọi là confusion matrix. Giả sử ta có bài toán phân loại 3 lớp, thì confusion matrix có dạng sau:\n","\n","<table>\n","    <th>\n","        <td>Lớp 1</td>\n","        <td>Lớp 2</td>\n","        <td>Lớp 3</td>\n","    </th>\n","    <tr>\n","        <td>Lớp 1</td>\n","        <td>$N_{11}$</td>\n","        <td>$N_{12}$</td>\n","        <td>$N_{13}$</td>\n","    </tr>\n","    <tr>\n","        <td>Lớp 2</td>\n","        <td>$N_{21}$</td>\n","        <td>$N_{22}$</td>\n","        <td>$N_{23}$</td>\n","    </tr>\n","    <tr>\n","        <td>Lớp 3</td>\n","        <td>$N_{31}$</td>\n","        <td>$N_{32}$</td>\n","        <td>$N_{33}$</td>\n","    </tr>\n","</table>\n","\n","Trong đó, $N_{kl}$ là tổng số mẫu thực chất thuộc lớp $k$ và/nhưng bộ phân loại phân loại thành lớp $l$ chia cho tổng số mẫu thực chất thuộc lớp $k$. Bộ phân loại càng tốt thì các ô trên đường chéo chính sẽ càng cao hơn so với các ô xung quanh. Khi tiến hành kiểm thử, người ra đề đã tính được confusion matrix như sau:\n","\n","<table>\n","    <tr>\n","        <td>0.93</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.02</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.05</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>0.95</td>\n","        <td>0</td>\n","        <td>0.05</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0.02</td>\n","        <td>0.02</td>\n","        <td>0.59</td>\n","        <td>0.02</td>\n","        <td>0.22</td>\n","        <td>0</td>\n","        <td>0.13</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0.05</td>\n","        <td>0.03</td>\n","        <td>0.03</td>\n","        <td>0.82</td>\n","        <td>0.05</td>\n","        <td>0</td>\n","        <td>0.03</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.07</td>\n","        <td>0.05</td>\n","        <td>0.77</td>\n","        <td>0</td>\n","        <td>0.12</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.89</td>\n","        <td>0</td>\n","        <td>0.09</td>\n","        <td>0.02</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0.21</td>\n","        <td>0</td>\n","        <td>0.08</td>\n","        <td>0.02</td>\n","        <td>0.17</td>\n","        <td>0</td>\n","        <td>0.51</td>\n","        <td>0</td>\n","        <td>0.02</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.04</td>\n","        <td>0</td>\n","        <td>0.86</td>\n","        <td>0</td>\n","        <td>0.1</td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.02</td>\n","        <td>0</td>\n","        <td>0.04</td>\n","        <td>0</td>\n","        <td>0.02</td>\n","        <td>0.93</td>\n","        <td>0</td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.02</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0</td>\n","        <td>0.98</td>\n","    </tr>\n","</table>\n","\n","Bạn cần đạt được kết quả tương tự hoặc tốt hơn sau khi hoàn tất bài tập 2 này."]},{"cell_type":"markdown","metadata":{"id":"jcf1mHx80syW"},"source":["#### TODO 18: softmax_test"]},{"cell_type":"code","metadata":{"id":"w7todI-yvOCS"},"source":["# GRADED FUNCTION: softmax_test\n","def softmax_test(y_hat, test_y):\n","    \"\"\"TODO 18: test\n","    Compute the confusion matrix based on labels and predicted values \n","\n","    :param classifier: the trained classifier\n","    :param y_hat: predicted probabilites, output of classifier.feed_forward\n","    :param test_y: test labels\n","    \"\"\"\n","\n","    y_hat = np.argmax(y_hat, axis=1)\n","    test_y = np.argmax(test_y, axis=1)\n","    confusion_mat = np.zeros((10,10))\n","    ### START CODE HERE ###\n","\n","    ### END CODE HERE ###\n","    return confusion_mat\n","\n","### Unit test\n","y_hat = np.eye(20, 10)\n","test_y = y_hat > 0.5\n","assert np.trace(softmax_test(y_hat, test_y)) == 10, \"Wrong\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VpXPqYoQzOod"},"source":["## Vòng lặp huấn luyện"]},{"cell_type":"code","metadata":{"id":"Kk6MG4qp0LYg"},"source":["def plot_softmax_loss(train_loss, val_loss):\n","    plt.figure(1)\n","    plt.clf()\n","    plt.plot(train_loss, color='b')\n","    plt.plot(val_loss, color='g')\n","\n","\n","def draw_weight(w):\n","    label_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","    plt.figure(2, figsize=(8, 6))\n","    plt.clf()\n","    w = w[0:(28*28),:].reshape(28, 28, 10)\n","    for i in range(10):\n","        ax = plt.subplot(3, 4, i+1)\n","        plt.imshow(w[:,:,i], interpolation='nearest')\n","        plt.axis('off')\n","        ax.set_title(label_names[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvi8LlauvQvr"},"source":["#@title Training { display-mode: \"both\" }\n","num_epoch = 10000 #@param {type:\"integer\"}\n","learning_rate = 0.01 #@param {type:\"number\"}\n","momentum_rate = 0.9 #@param {type:\"number\"}\n","epochs_to_draw = 10 #@param {type:\"integer\"}\n","update_weight_method = \"normal\" #@param [\"normal\", \"momentum\"]\n","\n","np.random.seed(2020)\n","\n","# Load data from file\n","# Make sure that fashion-mnist/*.gz files is in data/\n","train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data()\n","num_train = train_x.shape[0]\n","num_val = val_x.shape[0]\n","num_test = test_x.shape[0]  \n","\n","# Convert label lists to one-hot (one-of-k) encoding\n","train_y = create_one_hot(train_y)\n","val_y = create_one_hot(val_y)\n","test_y = create_one_hot(test_y)\n","\n","# Normalize our data\n","train_x, val_x, test_x = normalize(train_x, val_x, test_x)\n","\n","# Pad 1 as the last feature of train_x and test_x\n","train_x = add_one(train_x) \n","val_x = add_one(val_x)\n","test_x = add_one(test_x)\n","\n","# Create classifier\n","num_feature = train_x.shape[1]\n","dec_classifier = SoftmaxClassifier((num_feature, 10))\n","momentum = np.zeros_like(dec_classifier.w)\n","\n","# Define hyper-parameters and train-related parameters\n","all_train_loss = []\n","all_val_loss = []\n","plt.ion()\n","\n","for e in range(num_epoch):    \n","    train_y_hat = dec_classifier.feed_forward(train_x)\n","    val_y_hat = dec_classifier.feed_forward(val_x)\n","\n","    train_loss = dec_classifier.compute_loss(train_y, train_y_hat)\n","    val_loss = dec_classifier.compute_loss(val_y, val_y_hat)\n","\n","    grad = dec_classifier.get_grad(train_x, train_y, train_y_hat)\n","\n","    # dec_classifier.numerical_check(train_x, train_y, grad)\n","    # Updating weight: choose either normal GD or GD with momentum\n","    if update_weight_method == \"normal\":\n","        dec_classifier.update_weight(grad, learning_rate)\n","    else:\n","        dec_classifier.update_weight_momentum(grad, learning_rate, momentum, momentum_rate)\n","\n","    all_train_loss.append(train_loss) \n","    all_val_loss.append(val_loss)\n","    \n","    if is_stop_training(all_val_loss):\n","        break\n","\n","    if (e % epochs_to_draw == epochs_to_draw-1):\n","        from IPython.display import clear_output\n","        clear_output(wait=True)\n","        plot_softmax_loss(all_train_loss, all_val_loss)\n","        draw_weight(dec_classifier.w)\n","        plt.show()\n","        plt.pause(0.1) \n","        print(\"Epoch %d: train loss: %.5f || val loss: %.5f\" % (e+1, train_loss, val_loss))\n","\n","y_hat = dec_classifier.feed_forward(test_x)\n","np.set_printoptions(precision=2)\n","confusion_mat = softmax_test(y_hat, test_y)\n","print('Confusion matrix:')\n","print(confusion_mat)\n","print('Diagonal values:')\n","print(confusion_mat.flatten()[0::11])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o-5Ot3UI05wM"},"source":["** Thực hiện bài 2 với Tensorflow**"]},{"cell_type":"markdown","metadata":{"id":"iGmLYGhr1AET"},"source":["## Định nghĩa mô hình Softmax Regression bằng Tensorflow eager execution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BINeWJlQAxiF"},"source":["Tại đây, các bạn cần định nghĩa mô hình SoftmaxRegressionTF. Để định nghĩa mô hình này, các bạn nên tham khảo ví dụ ở mô hình LogisticRegressionTF ở trên."]},{"cell_type":"code","metadata":{"id":"0RU3mpbEyPZ6"},"source":["class SoftmaxRegressionTF(tf.keras.Model):\n","    def __init__(self, num_class):\n","        super(SoftmaxRegressionTF, self).__init__()\n","        # TODO 19: init all weights \n","        ### START CODE HERE ###\n","\n","        ### END CODE HERE ###\n","\n","    def call(self, inputs, training=None, mask=None):\n","        # TODO 20: implement your feedforward         \n","        ### START CODE HERE ###\n","\n","        ### END CODE HERE ###\n","        \n","        output = tf.nn.softmax(output)        \n","        \n","        return output\n","\n","### Unit test    \n","logistic_regressor = SoftmaxRegressionTF(10)\n","dummy_x = tf.zeros((1, 13))\n","assert logistic_regressor(dummy_x).numpy().sum() == 1, \"Wrong\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fx6PKo9OBN-v"},"source":["#### TODO 19: cài đặt hàm __init__ \n","Các bạn cần khởi tạo tất cả các trọng số ở hàm init của lớp SoftmaxRegressionTF."]},{"cell_type":"markdown","metadata":{"id":"j4GbtrTdBV7Z"},"source":["#### TODO 20: cài đặt hàm call\n","Cài đặt feedforward trong hàm call ở lớp SoftmaxRegressionTF."]},{"cell_type":"markdown","metadata":{"id":"N7dHYqGc6aax"},"source":["## Huấn luyện với tensorflow"]},{"cell_type":"code","metadata":{"id":"mEqbmm1M6Zu8"},"source":["#@title Training { display-mode: \"both\" }\n","num_epoch = 100 #@param {type:\"integer\"}\n","learning_rate = 0.001 #@param {type:\"number\"}\n","num_classes = 10\n","\n","tf.random.set_seed(2020)\n","\n","# Load data from file\n","# Make sure that fashion-mnist/*.gz files is in data/\n","train_x, train_y, val_x, val_y, test_x, test_y = get_mnist_data()\n","num_train = train_x.shape[0]\n","num_val = val_x.shape[0]\n","num_test = test_x.shape[0]  \n","\n","\n","# Convert label lists to one-hot (one-of-k) encoding\n","train_y = create_one_hot(train_y)\n","val_y = create_one_hot(val_y)\n","test_y = create_one_hot(test_y)\n","\n","# Normalize our data\n","train_x, val_x, test_x = normalize(train_x, val_x, test_x)\n","\n","device = '/cpu:0' if len(tf.config.experimental.list_physical_devices('GPU')) == 0 else '/gpu:0'\n","\n","with tf.device(device):\n","    # build model and optimizer\n","    model = SoftmaxRegressionTF(num_classes)\n","    model.compile(optimizer=tf.optimizers.Adam(learning_rate), loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    \n","\n","    # train\n","    model.fit(train_x, train_y, batch_size=batch_size, epochs=num_epoch,\n","              validation_data=(val_x, val_y), verbose=2)\n","\n","    # evaluate on test set\n","    scores = model.evaluate(test_x, test_y, 32, verbose=2)\n","    \n","    y_hat = model.predict(test_x)\n","\n","\n","    confusion_mat = softmax_test(y_hat, test_y)\n","    print('Confusion matrix:')\n","    print(confusion_mat)\n","    print('Diagonal values:')\n","    print(confusion_mat.flatten()[0::11])"],"execution_count":null,"outputs":[]}]}