{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"3.CNN.ipynb","provenance":[{"file_id":"1N-dhH79pHt3V1AHNlT0i6vJGuGwUMAxv","timestamp":1612123797063},{"file_id":"1IP5HiJm60Sca9YkfF1JBCbqKWzU6HAoZ","timestamp":1557199269107}],"collapsed_sections":["6DN3gs3aT6Mg","Oj4C8OMZT6Mh","qO-PkgqyT6Mj"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UuiKELEdT6MF"},"source":["# Giới thiệu Convolution Nets\n","\n","Convolutional Neural Networks (CNN) là một trong những mô hình deep learning phổ biến nhất và có ảnh hưởng nhiều nhất trong cộng đồng Computer Vision. CNN được dùng trong trong nhiều bài toán như nhận dạng ảnh, phân tích video, ảnh MRI, hoặc cho bài các bài của lĩnh vực xử lý ngôn ngữ tự nhiên, và hầu hết đều giải quyết tốt các bài toán này. \n","\n","CNN cũng có lịch sử khá lâu đời. Kiến trúc gốc của mô hình CNN được giới thiệu bởi một nhà khoa học máy tính người Nhật vào năm 1980. Sau đó, năm 1998, Yan LeCun lần đầu huấn luyện mô hình CNN với thuật toán backpropagation cho bài toán nhận dạng chữ viết tay. Tuy nhiên, mãi đến năm 2012, khi một nhà khoa học máy tính người Ukraine Alex Krizhevsky (đệ của Geoffrey Hinton) xây dựng mô hình CNN (AlexNet) và sử dụng GPU để tăng tốc quá trình huấn luyện deep nets để đạt được top 1 trong cuộc thi Computer Vision thường niên ImageNet với độ lỗi phân lớp top 5 giảm hơn 10% so với những mô hình truyền thống trước đó, đã tạo nên làn sóng mãnh mẽ sử dụng deep CNN với sự hỗ trợ của GPU để giải quyết càng nhiều các vấn đề trong Computer Vision.\n","\n","# Bài Toán Phân loại Ảnh\n","Phân loại ảnh là một bài toán quan trọng bậc nhất trong lĩnh vực Computer Vision. Chúng ta đã có rất nhiều nghiên cứu để giải quyết bài toán này bằng cách rút trích các đặc trưng rất phổ biến như SIFT, HOG rồi cho máy tính học nhưng những cách này tỏ ra không thực sự hiểu quả. Nhưng ngược lại, đối với con người, chúng ta lại có bản năng tuyệt vời để phân loại được những đối tượng trong khung cảnh xung quanh một cách dễ dàng.\n","\n","Dữ liệu đầu vào của bài toán là một bức ảnh. Một ảnh được biểu diễn bằng ma trận các giá trị. Mô hình phân lớp sẽ phải dự đoán được lớp của ảnh từ ma trận điểm ảnh này, ví dụ như ảnh đó là con mèo, chó, hay là chim.\n","\n","![](https://pbcquoc.github.io/images/cnn_input.png)\n","\n","# Nội dung \n","Trong assignment này, mình sẽ hướng dẫn các bạn xây dựng mô hình CNN (Convolution Neural Nets) cho bài toán phân loại ảnh. Các bạn sẽ sử dụng tensorflow để xây dựng model, huấn luyện mô hình trên tập train và predict ảnh trong tập test. \n","\n","Assignment này sẽ có câú trúc như sau:\n","1. Import/ Xử lý dữ liệu\n","2. Xây dựng mô hình\n","3. Huấn luyện mô hình\n","4. Đánh giá mô hình\n","5. Sử dụng mô hình đã huấn luyện để dự đoán"]},{"cell_type":"markdown","metadata":{"id":"1noDSEH2T6MG"},"source":["# Import thư viện\n","\n","Chúng ta sử dụng một số hàm cơ bản trong tensorflow, sklearn và phải gọi hàm tf.enable_eager_execution. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpEf76pvT6MH","executionInfo":{"elapsed":3938,"status":"ok","timestamp":1614875494348,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"ec8b1b4d-fadc-4a7d-bdbb-0219690c1b28"},"source":["import os\n","import numpy as np\n","np.warnings.filterwarnings('ignore')\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","\n","import pandas as pd\n","from tqdm import tqdm\n","\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","\n","tf.random.set_seed(0)\n","np.random.seed(0)\n","\n","print(\"Tensorflow version: \", tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensorflow version:  2.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E-drPZYqT6MK"},"source":["# Import và inspect dữ liệu\n","Trong bài này, các bạn phải xây dựng mô hình để phân loại 10 địa danh của Việt Nam. Tập dữ liệu huấn luyện bao gồm hơn 8 ngàn ảnh. \n"]},{"cell_type":"markdown","metadata":{"id":"6kFHSLe3T6ML"},"source":["## Download dữ liệu\n","Bạn có thể sử dụng trực tiếp dữ liệu trên competition được host trên Kaggle: [VietAI Foundation Course - CNN Assignment](https://www.kaggle.com/c/vietai-foundation-course-7-cnn-assignment/data)\n","\n","Hoặc tải dữ liệu xuống từ Google Drive"]},{"cell_type":"code","metadata":{"id":"TCiEHjzHT6ML"},"source":["gdd.download_file_from_google_drive(file_id='1wjuPDgCDThA2vk-2ctpTxr1HMoYYnm7h', dest_path='./Assignment3.zip', unzip=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQQFKcGLC1ZK"},"source":["Dữ liệu tải xuống sẽ chứa trong folder `data`. Cấu trúc thư mục như sau:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OgiAISfDBVD","executionInfo":{"elapsed":3915,"status":"ok","timestamp":1614875494349,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"7fecd00a-73f3-45a9-d3f5-a971c8a81af8"},"source":["data_dir = 'Assignment3'\n","os.listdir(data_dir)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['train.csv', 'sample_submission.csv', 'images']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"pkHAl5onDQjs"},"source":["Trong đó:\n","- **images**: thư mục chứa tất cả các ảnh dùng cho việc huấn luyện và đánh giá\n","- **train.csv**: file CSV chứa tên các file và nhãn dùng cho việc huấn luyện\n","- **sample_submission.csv**: file CSV mẫu chứa tên các file cần đánh giá và nhãn dummy."]},{"cell_type":"markdown","metadata":{"id":"Rg3f7Xn6EFC-"},"source":["## Đọc và xử lý dữ liệu"]},{"cell_type":"markdown","metadata":{"id":"NLFGYbfMWDQ7"},"source":["Đọc dữ liệu từ file CSV:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"MH__gPbQJSLV","executionInfo":{"elapsed":3897,"status":"ok","timestamp":1614875494351,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"e3a1ad66-bbbb-4528-fa04-075f7ce107ff"},"source":["train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>VietAI-Assignment3-1.jpg</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>VietAI-Assignment3-100.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>VietAI-Assignment3-10000.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>VietAI-Assignment3-10001.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>VietAI-Assignment3-10002.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          image  label\n","0      VietAI-Assignment3-1.jpg      7\n","1    VietAI-Assignment3-100.jpg      2\n","2  VietAI-Assignment3-10000.jpg      1\n","3  VietAI-Assignment3-10001.jpg      2\n","4  VietAI-Assignment3-10002.jpg      2"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBRrzcibWMWa","executionInfo":{"elapsed":3888,"status":"ok","timestamp":1614875494352,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"efa9592f-6833-44b0-e38f-c66343842a85"},"source":["train_df.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8234 entries, 0 to 8233\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   image   8234 non-null   object\n"," 1   label   8234 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 128.8+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"syh-kjLNbiQd","executionInfo":{"elapsed":3875,"status":"ok","timestamp":1614875494354,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"7914145f-7aaf-4532-ded4-9729329af68c"},"source":["test_df = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n","test_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>VietAI-Assignment3-10.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>VietAI-Assignment3-1000.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>VietAI-Assignment3-10004.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>VietAI-Assignment3-10006.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>VietAI-Assignment3-10012.jpg</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          image  label\n","0     VietAI-Assignment3-10.jpg      0\n","1   VietAI-Assignment3-1000.jpg      0\n","2  VietAI-Assignment3-10004.jpg      0\n","3  VietAI-Assignment3-10006.jpg      0\n","4  VietAI-Assignment3-10012.jpg      0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzBkL72Sbpg_","executionInfo":{"elapsed":3863,"status":"ok","timestamp":1614875494355,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"3cf65751-f818-4daf-e7fb-610cb44e657b"},"source":["test_df.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2059 entries, 0 to 2058\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   image   2059 non-null   object\n"," 1   label   2059 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 32.3+ KB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"buXAweOvENiO"},"source":["Tổng cộng có 8,324 ảnh cho việc huấn luyện và 2,059 ảnh cần dự đoán nhãn, ta tiến hành thống kê phân bố các nhãn trên tập huấn luyện:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZPoB7-gV8C6","executionInfo":{"elapsed":3855,"status":"ok","timestamp":1614875494356,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"40593375-759f-47f4-a7f6-47d4ba29d7d3"},"source":["train_df.label.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2     1949\n","1      846\n","0      808\n","3      764\n","5      642\n","4      599\n","7      579\n","10     575\n","6      535\n","8      469\n","9      468\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Bo0z1gUIVcmj"},"source":["Số lượng các ảnh cho mỗi lớp từ xấp xỉ 470 đến xấp xỉ 2000. Trong đó lớp số 2 có số lượng ảnh nhiều nhất.\n","\n","Đoạn code bên dưới show ra 1 số hình ảnh và class của nó."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1a2ZX12fVUYewGQBwB1wu8X_wqFGphdXx"},"id":"n_HwfNQpizDR","executionInfo":{"elapsed":8311,"status":"ok","timestamp":1614875498825,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"b7de514c-c4de-4a4a-9636-189da9ad0aa1"},"source":["import cv2\n","def show_gallery(df, n=5, shuffle=True):\n","  plt.subplots(figsize=(20,20))\n","  if shuffle:\n","    df = df.sample(frac=1).reset_index(drop=True)\n","  k=1\n","  for i in range(n*n):\n","    im = cv2.imread(os.path.join(\"./Assignment3/images\",df.loc[k,\"image\"]))\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    label = df.loc[k,\"label\"]\n","    plt.subplot(n,n,k)\n","    plt.imshow(im)\n","    plt.title(\"Label: {}\".format(label))\n","    plt.axis(\"off\")\n","    k += 1\n","\n","show_gallery(train_df)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"TtOnhMO_W_0D"},"source":["## TODO 1: Cài đặt hàm đọc ảnh và đưa về NumPy Array\n","Để máy tính hiểu được các ảnh, chúng ta cần đọc và chuyển các ảnh về tensor. Bên cạnh đó, các tensor biểu diễn cần có kích thước cố định nên trong quá trình đọc ảnh, ta cần thay đổi về kích thước mong muốn (resize ảnh). Trong các bài toán về deep learning, ta thường biểu diễn ảnh dưới dạng tensor có kích thước `(224,224,3)` với 3 kênh màu, 224 pixels cho mỗi kênh.\n","\n","Hoàn thành hàm `generate_data` bên dưới nhận vào 1 list N đường dẫn đến ảnh và kích thước `size` ảnh cần resize. Trả về numpy array có kích thước `(N,size,size,3)`. Do ảnh màu có thể biểu diễn bằng số nguyên 0 --> 255 nên để tiết kiệm bộ nhớ cho phù hợp với ram colab, chỉ cần dùng kiểu dữ liệu uint8."]},{"cell_type":"code","metadata":{"id":"AIHjhdzRZ8Z3"},"source":["def generate_data(image_paths, size=224):\n","    \"\"\"\n","    Đọc và chuyển các ảnh về numpy array\n","    \n","    Parameters\n","    ----------\n","    image_paths: list of N strings\n","        List các đường dẫn ảnh\n","    size: int\n","        Kích thước ảnh cần resize\n","    \n","    Returns\n","    -------\n","    numpy array kích thước (N, size, size, 3)\n","    \"\"\"\n","    image_array = np.zeros((len(image_paths), size, size, 3), dtype='uint8')\n","    \n","    for idx, image_path in tqdm(enumerate(image_paths)):\n","        ### START CODE HERE\n","        \n","        # Đọc ảnh bằng thư viện Pillow và resize ảnh\n","        image = Image.open(image_path)\n","        image = image.resize((224,224))\n","        \n","        # Chuyển ảnh thành numpy array và gán lại mảng image_array\n","        image_array[idx] = np.asarray(image, dtype='uint8')\n","        \n","        ### END CODE HERE\n","    return image_array"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s9sI7QBibZdG"},"source":["Sử dụng hàm `generate_data` để tạo ma trận của tập dữ liệu train và test:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7UkA-_rbYzn","executionInfo":{"elapsed":63244,"status":"ok","timestamp":1614875553775,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"3bda9d7b-bad8-487d-baff-474716c153d7"},"source":["# List các đường dẫn file cho việc huấn luyện\n","train_files = [os.path.join(\"Assignment3/images\", file) for file in train_df.image]\n","\n","# List các nhãn\n","train_y = train_df.label\n","\n","# Tạo numpy array cho dữ liệu huấn luyện\n","train_arr = generate_data(train_files)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["8234it [00:56, 146.32it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"c9GkJ4Bfe2qc"},"source":["Hãy kiểm tra kích thước của tensor `train_arr` vừa tạo ra. Kích thước đúng sẽ là `(8234,224,224,3)`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxScb0w_e2Gh","executionInfo":{"elapsed":63235,"status":"ok","timestamp":1614875553775,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"74549a5a-e488-442d-d27e-13332c570e5e"},"source":["train_arr.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8234, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"msp9WEgOfRdf"},"source":["Tiến hành tạo tensor dữ liệu cho tập test:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uX525nHRQe1","executionInfo":{"elapsed":76355,"status":"ok","timestamp":1614875566906,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"f1fb63a7-8d11-4524-ce44-57fdd1b56375"},"source":["test_files = [os.path.join(\"Assignment3/images\", file) for file in test_df.image]\n","test_x = generate_data(test_files)\n","test_x.shape"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2059it [00:12, 159.83it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(2059, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"LssbDy2pf9ua"},"source":["Tạo **one-hot labels** từ `train_y` để đưa vào huấn luyện với Tensorflow. "]},{"cell_type":"code","metadata":{"id":"iVuRanKET6MO"},"source":["num_classes = len(np.unique(train_y))\n","y_ohe = tf.keras.utils.to_categorical(train_y, num_classes=num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vjpnYIXRT6MT"},"source":["## Chia dữ liệu để huấn luyện và đánh giá\n","\n","Ta sẽ không sử dụng 100% tập dữ liệu đã có nhãn để huấn luyện mà sẽ chỉ huấn luyện trên 75% bộ dữ liệu và sử dụng 25% còn lại dùng để đánh giá model qua các epoch.\n","\n","Chúng ta sử dụng hàm `train_test_split` trong thư viện sklearn để chia tập dữ liệu thành 2 phần train/validation một cách nhanh chóng."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MtnwiHOZT6MU","executionInfo":{"elapsed":76664,"status":"ok","timestamp":1614875567231,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"080c7514-fa0c-4206-ea84-59c6b658a22e"},"source":["x_train, x_valid, y_train_ohe, y_valid_ohe = train_test_split(train_arr, y_ohe, test_size=0.25)\n","\n","print(\"Train size: {} - Validation size: {}\".format(x_train.shape, x_valid.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train size: (6175, 224, 224, 3) - Validation size: (2059, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"06g6e_u7T6MY"},"source":["## Mô Hình CNN\n","\n","CNN bao gồm tập hợp các lớp cơ bản sau: convolutional layer + nonlinear layer (RELU, ...), pooling layer, fully connected layer. Các lớp này liên kết với nhau theo một thứ tự nhất định. Thông thường, một ảnh sẽ được lan truyền qua tầng convolutional layer + nonlinear layer đầu tiên, sau đó các giá trị tính toán được sẽ lan truyền qua pooling layer, bộ ba convolutional layer + nonlinear layer + pooling layer có thể được lặp lại nhiều lần trong network. Và sau đó được lan truyền qua tầng fully connected layer và softmax để tính xác suất ảnh đó thuộc lớp nào.\n","\n","![](https://pbcquoc.github.io/images/cnn_model.png)\n","\n","### Convolutional Layer\n","Convolutional layer thường là lớp đầu tiên và cũng là lớp quan trọng nhất của mô hình CNN. Lớp này có chức năng chính là phát hiện các đặc trưng về không gian một cách hiệu quả. Trong tầng này có 4 đối tượng chính là: ma trận đầu vào, bộ **filter**, và **receptive field**, **feature map**. Conv layer nhận đầu vào là một ma trận 3 chiều và một bộ filter cần phải học. Bộ filters này sẽ trượt qua từng vị trí trên bức ảnh để tính tích chập (convolution) giữa bộ filter và phần tương ứng trên bức ảnh. Phần tương ứng này trên bức ảnh gọi là receptive field, tức là vùng mà một neuron có thể nhìn thấy để đưa ra quyết định, và ma trận sinh ra bởi quá trình này được gọi là feature map. Để hình dung, các bạn có thể tưởng tượng, bộ filters giống như các tháp canh trong nhà tù quét lần lượt qua không gian xung quanh để tìm kiếm tên tù nhân bỏ trốn. Khi phát hiện tên tù nhân bỏ trốn, thì chuông báo động sẽ reo lên, giống như các bộ filters tìm kiếm được đặc trưng nhất định thì tích chập đó sẽ cho giá trị lớn. \n","\n","<div class=\"img-div\" markdown=\"0\">\n","    <img src=\"https://media.giphy.com/media/3orif7it9f4phjv4LS/giphy.gif\" />\n","</div>\n","\n","Với ví dụ ở bên dưới, dữ liệu đầu vào là ma trận có kích thước 8x8x1, một bộ filter có kích thước 2x2x1, feature map có kích thước 7x7x1. Mỗi giá trị ở feature map được tính bằng tổng của tích các phần tử tương ứng của bộ filter 2x2x1 với receptive field trên ảnh. Và để tính tất cả các giá trị cho feature map, các bạn cần trượt filter từ trái sang phải, từ trên xuống dưới. Do đó, các bạn có thể thấy rằng phép convolution bảo toàn thứ tự không gian của các điểm ảnh. Ví dụ điểm góc trái của dữ liệu đầu vào sẽ tương ứng với bên một điểm bên góc trái của feature map. \n","\n","<div class=\"img-div\" markdown=\"0\">\n","    <img src=\"https://pbcquoc.github.io/images/cnn_covolution_layer.png\" />\n","</div>\n","\n","#### Tầng convolution như là feature detector \n","\n","Tầng convolution có chức năng chính là phát hiện đặc trưng cụ thể của bức ảnh. Những đặc trưng này bao gồm đặc trưng cơ bản là góc, cạnh, màu sắc, hoặc đặc trưng phức tạp hơn như texture của ảnh. Vì bộ filter quét qua toàn bộ bức ảnh, nên những đặc trưng này có thể nằm ở vị trí bất kì trong bức ảnh, cho dù ảnh bị xoay trái/phải thì những đặc trưng này vẫn được phát hiện. \n","\n","Ở minh họa dưới, các bạn có một filter 5x5 dùng để phát hiện góc/cạnh, filter này chỉ có giá trị một tại các điểm tương ứng một góc cong. \n","\n","<div class=\"img-div\" markdown=\"0\">\n","    <img src=\"https://pbcquoc.github.io/images/cnn_high_level_feature.png\" />\n","</div>\n","\n","Dùng filter ở trên trượt qua ảnh của nhân vật Olaf trong trong bộ phim Frozen. Chúng ta thấy rằng, chỉ ở những vị trí trên bức ảnh có dạng góc như đặc trưng ở filter thì mới có giá trị lớn trên feature map, những vị trí còn lại sẽ cho giá trị thấp hơn. Điều này có nghĩa là, filter đã phát hiện thành công một dạng góc/cạnh trên dữ liệu đầu vào. Tập hợp nhiều bộ filters sẽ cho phép các bạn phát hiện được nhiều loại đặc trưng khác nhau, và giúp định danh được đối tượng. \n","\n","<div class=\"img-div\" markdown=\"0\">\n","    <img src=\"https://pbcquoc.github.io/images/cnn_high_level_feature_ex.png\" />\n","</div>\n","\n","#### Các tham số của tầng convolution: Kích thước bộ filters, stride và padding\n","\n","Kích thước bộ filters là một trong những siêu tham số quan trọng nhất của tầng convolution. Kích thước này tỉ lệ thuận với số lượng tham số cần học tại mỗi tầng convolution và là tham số quyết định receptive field của tầng này. Kích thước phổ biến nhất của bộ filter là 3x3.\n"]},{"cell_type":"markdown","metadata":{"id":"D8v6bMpmQZwU"},"source":["# Xây dựng mô hình\n","Các bạn cần phải xây dựng mô hình CNN có kiến trúc sau đây. Bộ filter có kích thước 3x3. Đối với các tham số còn lại, các bạn có thể tự do lựa chọn để cho ra kết quả huấn luyện tốt nhất.\n","\n","![](https://github.com/pbcquoc/cnn/raw/master/images/cnn_architecture_2.png)\n"]},{"cell_type":"markdown","metadata":{"id":"HCXKoRsNT6Ma"},"source":["## Định nghĩa block CNN\n","Để hỗ trợ quá trình định nghĩa mô hình. Các bạn cần định nghĩa một block bao gồm 3 lớp sau: Conv2D, MaxPool2D, ReLU. Block này sẽ được tái sử dụng nhiều lần trong networks. Các layers cần được khai báo trong hàm init và được gọi trong hàm call. Hãy tham khảo ví dụ dưới đây.\n","\n","```python\n","\n","class ConvBlock(tf.keras.Model):\n","    def __init__(self):\n","        super(ConvBlock, self).__init__()\n","        self.cnn = tf.keras.layers.Conv2D(32, (3, 3), strides=(1, 1),  padding=\"same\")\n","        \n","    def call(self, inputs, training=None, mask=None):\n","        x = self.cnn(inputs)\n","\n","        return x\n","```\n","\n","Các tài liệu tham khảo:\n","- [tf.keras.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n","- [tf.keras.layers.MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)"]},{"cell_type":"code","metadata":{"id":"GkT5hTxjT6Mb"},"source":["class ConvBlock(tf.keras.Model):\n","    def __init__(self, filters, kernel, strides, padding):\n","        '''\n","        Khởi tạo Convolution Block với các tham số đầu vào\n","        \n","        Parameters\n","        ----------\n","        filters: int\n","            số lượng filter\n","        kernel: int\n","            kích thước kernel\n","        strides: int\n","            stride của convolution layer\n","        padding: str\n","            Loại padding của convolution layer\n","        \n","        '''\n","        \n","        super(ConvBlock, self).__init__()\n","        ## TODO 2\n","        ### START CODE HERE\n","        \n","        # Tạo layer Conv2D\n","        self.cnn = tf.keras.layers.Conv2D(filters=filters, \n","                                          kernel_size=kernel, \n","                                          strides=strides, \n","                                          padding=padding, \n","                                          kernel_initializer='random_normal',\n","                                          bias_initializer='random_normal',\n","                                          kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n","                                          bias_regularizer=tf.keras.regularizers.l2(1e-4),\n","                                          activity_regularizer=tf.keras.regularizers.l2(1e-4),\n","                                          activation='relu')\n","        \n","        # Tạo layer MaxPool2D\n","        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n","        \n","        # Tạo các layer khác tùy ý nếu cần thiết\n","\n","        ### END CODE HERE\n","        \n","        \n","    def call(self, inputs):\n","        '''\n","        Hàm này sẽ được gọi trong quá trình forwarding của mạng\n","        \n","        Parameters\n","        ----------\n","        inputs: tensor đầu vào\n","        \n","        Returns\n","        -------\n","        tensor\n","            giá trị đầu ra của mạng\n","        '''\n","        \n","        x = None\n","        ## TODO 3\n","        ### START CODE HERE\n","\n","        # Forward inputs qua từng layer và gán vào biến x để trả về\n","        x = self.cnn(inputs)\n","        x = self.pool(x)\n","        ## END CODE HERE\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1avJ7wvxpFq"},"source":["## Định nghĩa toàn bộ mô hình CNN\n","Các bạn sử dụng block ở trên để định nghĩa toàn bộ mô hình CNN có kiến trúc như hình dưới. Các layer cần được khởi tạo trong hàm init, và được gọi trong hàm call.\n","Số lượng block có thể thay đổi tùy ý các bạn nhưng phải nhiều hơn 1 block.\n","\n","Trong hàm call cần phải normalize input về khoảng [0, 1] vì input hiện tại đang trong khoảng [0, 255]"]},{"cell_type":"code","metadata":{"id":"fn6w7oh-T6Md"},"source":["class CNN(tf.keras.Model):\n","    def __init__(self, num_classes):\n","        \n","        super(CNN, self).__init__()\n","        \n","        ## TODO 4\n","        ### START CODE HERE\n","        \n","        # Khởi tạo các convolution block\n","        self.block1 = ConvBlock(32,(3,3),(1,1),'valid')\n","        self.block2 = ConvBlock(64,(3,3),(1,1),'valid')\n","        self.block3 = ConvBlock(128,(3,3),(1,1),'valid')\n","        self.block4 = ConvBlock(256,(3,3),(1,1),'valid')\n","        self.block5 = ConvBlock(512,(3,3),(1,1),'valid')\n","        \n","        # Khởi tạo layer để flatten feature map \n","        self.flatten = tf.keras.layers.Flatten()\n","        \n","        ### END CODE HERE\n","        \n","        ## TODO 5\n","        ### START CODE HERE\n","        \n","        # Khởi tạo fully connected layer\n","        self.dense1 = tf.keras.layers.Dense(512,\n","                                            activation='relu',\n","                                            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n","                                            bias_regularizer=tf.keras.regularizers.l2(1e-4),\n","                                            kernel_initializer='random_normal',\n","                                            bias_initializer='random_normal')\n","        self.drop1 = tf.keras.layers.Dropout(0.5)\n","        # self.dense2 = tf.keras.layers.Dense(256,\n","        #                                     activation='relu',\n","        #                                     kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n","        #                                     bias_regularizer=tf.keras.regularizers.l2(1e-4))\n","        # self.drop2 = tf.keras.layers.Dropout(0.5)\n","        self.dense3 = tf.keras.layers.Dense(num_classes)\n","        ### END CODE HERE\n","\n","    def call(self, inputs):\n","        \n","        ## TODO 6\n","        x = None\n","        ### START CODE HERE\n","\n","        # Normalize\n","        inputs = inputs / 255\n","\n","        # Forward gía trị inputs qua các tầng CNN và gán vào x\n","        x = self.block1(inputs)\n","        x = self.block2(x)\n","        x = self.block3(x)\n","        x = self.block4(x)\n","        x = self.block5(x)\n","        \n","        ### END CODE HERE\n","        \n","        ## TODO 7\n","        \n","        ### START CODE HERE \n","        \n","        # Forward giá trị x qua Fully connected layer\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        x = self.drop1(x)\n","        # x = self.dense2(x)\n","        # x = self.drop2(x)\n","        x = self.dense3(x)\n","        \n","        ### END CODE HERE\n","        output = tf.nn.softmax(x)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_jxGjdST6Mg"},"source":["## TODO 2: Cài Đặt Block CNN trong lớp ConvBlock\n","Sử dụng `tf.keras.layers.Conv2D` và `tf.keras.layers.MaxPool2D` để cài đặt tầng convolution và tầng pooling"]},{"cell_type":"markdown","metadata":{"id":"_qngAyXgCt8B"},"source":["## TODO 3: Gọi các tầng trong ConvBlock của lớp ConvBlock\n","Hãy gọi các tầng đã cài đặt trọng lớp ConvBlock trong hàm call"]},{"cell_type":"markdown","metadata":{"id":"6DN3gs3aT6Mg"},"source":["## TODO 4: Khai báo ConvBlock 1,2,3,4,5 trong mô hình CNN\n","Gọi ConvBlock đã cài đặt ở trên"]},{"cell_type":"markdown","metadata":{"id":"Oj4C8OMZT6Mh"},"source":["## TODO 5: Khai báo Tầng Fully Connected Layer cho mô hình CNN\n","Gọi `tf.keras.layers.Dense` để cài đặt tầng này"]},{"cell_type":"markdown","metadata":{"id":"qO-PkgqyT6Mj"},"source":["## TODO 6: Gọi các tầng Conv đã khai báo trong mô hình CNN ở trên\n","Gọi các tầng Conv đã cài đặt"]},{"cell_type":"markdown","metadata":{"id":"CkbJdSYmT6Mk"},"source":["## TODO 7: Gọi tầng Fully Connected Layer\n","Hãy flatten tầng phía trước và gọi tầng fully connected layer để convert về ma trận có số chiều bằng số lớp cần phân loại"]},{"cell_type":"markdown","metadata":{"id":"HeV9Ab03T6Mk"},"source":["# Huấn Luyện\n","Đoạn code này thực hiện quá trình huấn luyện mô hình CNN. Mỗi lần chạy mô hình sẽ lấy `batch_size` mẫu dữ liệu, feedforward, tính loss, và cập nhật gradient cho toàn bộ trọng số. Toàn bộ quá trình này được thực hiện trong hàm `fit()` được build sẵn trong model keras.\n","\n","Sau khi huấn luyện xong, chúng ta sẽ sử dụng mô hình để phân lớp các ảnh trong tập test bằng hàm `predict()`"]},{"cell_type":"markdown","metadata":{"id":"xU6OvROCJjHs"},"source":["---\n","\n","Transfer Learning with Resnet50 + data aug"]},{"cell_type":"code","metadata":{"id":"E9iP9P2M9CCM"},"source":["from keras.applications.resnet50 import ResNet50\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq6gNb-tGuDs"},"source":["# Data Generator dùng cho training\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True)\n","\n","# Data Generator dùng cho validation và testing\n","test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jTZsOwBtAn33","outputId":"e961b9fc-bcdf-48df-c670-ca143c7bb521"},"source":["device = '/cpu:0' if len(tf.config.experimental.list_physical_devices('GPU')) == 0 else '/gpu:0'\n","\n","with tf.device(device):\n","    base_model = ResNet50(input_shape=(224,224,3) , \n","                          include_top=False, \n","                          weights='imagenet')\n","    flat1 = tf.keras.layers.Flatten()(base_model.layers[-1].output)\n","\n","    output = tf.keras.layers.Dense(num_classes, activation='softmax')(flat1)\n","\n","    model = tf.keras.models.Model(inputs=base_model.inputs, outputs=output)\n","\n","    # base_model.trainable = True\n","\n","    mcp = tf.keras.callbacks.ModelCheckpoint(\"resnet50.h5\", monitor=\"val_accuracy\",\n","                          save_best_only=True, save_weights_only=True)\n","    rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, mode='max', patience=5, min_lr=1e-8, verbose=1)\n","\n","    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='categorical_crossentropy',\n","                      metrics=['accuracy'])\n","\n","    model.fit(train_datagen.flow(x_train, y_train_ohe), batch_size=32, epochs=50,\n","              validation_data=test_datagen.flow(x_valid, y_valid_ohe), verbose=1, callbacks=[mcp, rlr])\n","  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","193/193 [==============================] - 108s 482ms/step - loss: 5.1158 - accuracy: 0.4155 - val_loss: 2.3892 - val_accuracy: 0.1000\n","Epoch 2/50\n","193/193 [==============================] - 90s 466ms/step - loss: 2.4270 - accuracy: 0.4812 - val_loss: 2.3920 - val_accuracy: 0.2385\n","Epoch 3/50\n","193/193 [==============================] - 91s 468ms/step - loss: 2.7394 - accuracy: 0.4128 - val_loss: 55.4561 - val_accuracy: 0.1583\n","Epoch 4/50\n","193/193 [==============================] - 90s 468ms/step - loss: 1.9497 - accuracy: 0.4910 - val_loss: 6.6353 - val_accuracy: 0.1243\n","Epoch 5/50\n","193/193 [==============================] - 90s 467ms/step - loss: 1.7457 - accuracy: 0.5474 - val_loss: 2.1842 - val_accuracy: 0.3536\n","Epoch 6/50\n","193/193 [==============================] - 90s 467ms/step - loss: 1.3195 - accuracy: 0.6100 - val_loss: 37.9050 - val_accuracy: 0.4298\n","Epoch 7/50\n","193/193 [==============================] - 91s 470ms/step - loss: 1.3606 - accuracy: 0.6273 - val_loss: 1.0347 - val_accuracy: 0.6795\n","Epoch 8/50\n","193/193 [==============================] - 90s 468ms/step - loss: 1.0329 - accuracy: 0.6777 - val_loss: 1.0270 - val_accuracy: 0.6775\n","Epoch 9/50\n","193/193 [==============================] - 91s 469ms/step - loss: 0.9128 - accuracy: 0.7124 - val_loss: 1.2337 - val_accuracy: 0.6668\n","Epoch 10/50\n","193/193 [==============================] - 91s 469ms/step - loss: 0.8389 - accuracy: 0.7319 - val_loss: 0.7926 - val_accuracy: 0.7795\n","Epoch 11/50\n","193/193 [==============================] - 91s 468ms/step - loss: 0.7882 - accuracy: 0.7550 - val_loss: 3.4597 - val_accuracy: 0.6231\n","Epoch 12/50\n","193/193 [==============================] - 91s 468ms/step - loss: 0.7641 - accuracy: 0.7639 - val_loss: 1.2922 - val_accuracy: 0.5838\n","Epoch 13/50\n","193/193 [==============================] - 91s 468ms/step - loss: 0.8028 - accuracy: 0.7537 - val_loss: 1.1475 - val_accuracy: 0.6999\n","Epoch 14/50\n","193/193 [==============================] - 91s 469ms/step - loss: 0.6937 - accuracy: 0.7900 - val_loss: 3.2494 - val_accuracy: 0.5216\n","Epoch 15/50\n","193/193 [==============================] - 91s 469ms/step - loss: 0.8030 - accuracy: 0.7690 - val_loss: 1.0919 - val_accuracy: 0.6707\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 16/50\n","193/193 [==============================] - 91s 469ms/step - loss: 0.6107 - accuracy: 0.8086 - val_loss: 0.4668 - val_accuracy: 0.8519\n","Epoch 17/50\n","193/193 [==============================] - 91s 468ms/step - loss: 0.4536 - accuracy: 0.8572 - val_loss: 0.4394 - val_accuracy: 0.8664\n","Epoch 18/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.4479 - accuracy: 0.8502 - val_loss: 0.4149 - val_accuracy: 0.8664\n","Epoch 19/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.3977 - accuracy: 0.8674 - val_loss: 0.4207 - val_accuracy: 0.8655\n","Epoch 20/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.3666 - accuracy: 0.8764 - val_loss: 0.3901 - val_accuracy: 0.8805\n","Epoch 21/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.3406 - accuracy: 0.8890 - val_loss: 0.3820 - val_accuracy: 0.8839\n","Epoch 22/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.3303 - accuracy: 0.8834 - val_loss: 0.3754 - val_accuracy: 0.8859\n","Epoch 23/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.3033 - accuracy: 0.8973 - val_loss: 0.3570 - val_accuracy: 0.8995\n","Epoch 24/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.2737 - accuracy: 0.9099 - val_loss: 0.3840 - val_accuracy: 0.8888\n","Epoch 25/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.2795 - accuracy: 0.9052 - val_loss: 0.3858 - val_accuracy: 0.8902\n","Epoch 26/50\n","193/193 [==============================] - 91s 469ms/step - loss: 0.2660 - accuracy: 0.9090 - val_loss: 0.3768 - val_accuracy: 0.8941\n","Epoch 27/50\n","193/193 [==============================] - 91s 469ms/step - loss: 0.2425 - accuracy: 0.9200 - val_loss: 0.3498 - val_accuracy: 0.9048\n","Epoch 28/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.2235 - accuracy: 0.9219 - val_loss: 0.3749 - val_accuracy: 0.8975\n","Epoch 29/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.2346 - accuracy: 0.9196 - val_loss: 0.3706 - val_accuracy: 0.8990\n","Epoch 30/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.2083 - accuracy: 0.9337 - val_loss: 0.3568 - val_accuracy: 0.9029\n","Epoch 31/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.2069 - accuracy: 0.9333 - val_loss: 0.3771 - val_accuracy: 0.9004\n","Epoch 32/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.1916 - accuracy: 0.9341 - val_loss: 0.3588 - val_accuracy: 0.9072\n","Epoch 33/50\n","193/193 [==============================] - 90s 468ms/step - loss: 0.2105 - accuracy: 0.9257 - val_loss: 0.3879 - val_accuracy: 0.8966\n","Epoch 34/50\n","193/193 [==============================] - 91s 468ms/step - loss: 0.1604 - accuracy: 0.9478 - val_loss: 0.3742 - val_accuracy: 0.9082\n","Epoch 35/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.1540 - accuracy: 0.9456 - val_loss: 0.4506 - val_accuracy: 0.8776\n","Epoch 36/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.1780 - accuracy: 0.9390 - val_loss: 0.4173 - val_accuracy: 0.8932\n","Epoch 37/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.1643 - accuracy: 0.9400 - val_loss: 0.3700 - val_accuracy: 0.9043\n","Epoch 38/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.1505 - accuracy: 0.9478 - val_loss: 0.3898 - val_accuracy: 0.9058\n","Epoch 39/50\n","193/193 [==============================] - 90s 465ms/step - loss: 0.1398 - accuracy: 0.9504 - val_loss: 0.3414 - val_accuracy: 0.9136\n","Epoch 40/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.1347 - accuracy: 0.9532 - val_loss: 0.3891 - val_accuracy: 0.9077\n","Epoch 41/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.1354 - accuracy: 0.9511 - val_loss: 0.3656 - val_accuracy: 0.9053\n","Epoch 42/50\n","193/193 [==============================] - 90s 465ms/step - loss: 0.1291 - accuracy: 0.9573 - val_loss: 0.3662 - val_accuracy: 0.9203\n","Epoch 43/50\n","193/193 [==============================] - 90s 465ms/step - loss: 0.1350 - accuracy: 0.9539 - val_loss: 0.4703 - val_accuracy: 0.8956\n","Epoch 44/50\n","193/193 [==============================] - 90s 463ms/step - loss: 0.1113 - accuracy: 0.9601 - val_loss: 0.3827 - val_accuracy: 0.9092\n","Epoch 45/50\n","193/193 [==============================] - 89s 463ms/step - loss: 0.1151 - accuracy: 0.9606 - val_loss: 0.4117 - val_accuracy: 0.9092\n","Epoch 46/50\n","193/193 [==============================] - 90s 464ms/step - loss: 0.1137 - accuracy: 0.9625 - val_loss: 0.4640 - val_accuracy: 0.8825\n","Epoch 47/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.0961 - accuracy: 0.9647 - val_loss: 0.4664 - val_accuracy: 0.9063\n","\n","Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 48/50\n","193/193 [==============================] - 90s 466ms/step - loss: 0.0977 - accuracy: 0.9666 - val_loss: 0.3846 - val_accuracy: 0.9179\n","Epoch 49/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.0747 - accuracy: 0.9747 - val_loss: 0.3665 - val_accuracy: 0.9252\n","Epoch 50/50\n","193/193 [==============================] - 90s 467ms/step - loss: 0.0716 - accuracy: 0.9760 - val_loss: 0.3672 - val_accuracy: 0.9233\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e8H97yvbJYF2"},"source":["---\n","Original without transfer learning & data augmentation\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tmZonE2T6Ml","executionInfo":{"elapsed":1014454,"status":"ok","timestamp":1614184016835,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"01a20ebe-aabb-4066-ea8a-7e02406906eb"},"source":["device = '/cpu:0' if len(tf.config.experimental.list_physical_devices('GPU')) == 0 else '/gpu:0'\n","batch_size = 32\n","epochs = 32\n","\n","with tf.device(device):\n","    # Khởi tạo model\n","    model = CNN(num_classes)\n","    \n","    # Tạo callback để lưu model có accuracy trên tập validation tốt nhất\n","    mcp = tf.keras.callbacks.ModelCheckpoint(\"my_model.h5\", monitor=\"val_accuracy\",\n","                      save_best_only=True, save_weights_only=True)\n","    \n","    # datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    # rotation_range=20,\n","    # width_shift_range=0.2,\n","    # height_shift_range=0.2,\n","    # horizontal_flip=True)\n","\n","\n","    # Compile model\n","    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    \n","    # Huấn luyện\n","    # model.fit(datagen.flow(x_train, y_train_ohe), batch_size=batch_size, epochs=epochs,\n","    #           validation_data=(x_valid, y_valid_ohe), verbose=1, callbacks=[mcp])\n","    model.fit(x_train, y_train_ohe, batch_size=batch_size, epochs=epochs,\n","          validation_data=(x_valid, y_valid_ohe), verbose=1, callbacks=[mcp])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/32\n","193/193 [==============================] - 41s 170ms/step - loss: 4.9925 - accuracy: 0.2152 - val_loss: 2.9598 - val_accuracy: 0.3103\n","Epoch 2/32\n","193/193 [==============================] - 31s 162ms/step - loss: 2.9118 - accuracy: 0.3282 - val_loss: 2.5337 - val_accuracy: 0.4031\n","Epoch 3/32\n","193/193 [==============================] - 31s 163ms/step - loss: 2.4918 - accuracy: 0.4252 - val_loss: 2.2115 - val_accuracy: 0.4599\n","Epoch 4/32\n","193/193 [==============================] - 31s 163ms/step - loss: 2.1724 - accuracy: 0.4995 - val_loss: 1.8653 - val_accuracy: 0.5721\n","Epoch 5/32\n","193/193 [==============================] - 31s 163ms/step - loss: 1.8229 - accuracy: 0.5799 - val_loss: 1.7477 - val_accuracy: 0.5760\n","Epoch 6/32\n","193/193 [==============================] - 31s 163ms/step - loss: 1.6618 - accuracy: 0.6134 - val_loss: 1.5594 - val_accuracy: 0.6537\n","Epoch 7/32\n","193/193 [==============================] - 31s 162ms/step - loss: 1.4201 - accuracy: 0.6927 - val_loss: 1.3952 - val_accuracy: 0.7037\n","Epoch 8/32\n","193/193 [==============================] - 31s 163ms/step - loss: 1.2350 - accuracy: 0.7465 - val_loss: 1.3350 - val_accuracy: 0.7169\n","Epoch 9/32\n","193/193 [==============================] - 31s 162ms/step - loss: 1.1293 - accuracy: 0.7816 - val_loss: 1.3169 - val_accuracy: 0.7217\n","Epoch 10/32\n","193/193 [==============================] - 31s 163ms/step - loss: 0.9791 - accuracy: 0.8288 - val_loss: 1.2987 - val_accuracy: 0.7402\n","Epoch 11/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.8837 - accuracy: 0.8557 - val_loss: 1.2751 - val_accuracy: 0.7460\n","Epoch 12/32\n","193/193 [==============================] - 31s 163ms/step - loss: 0.8046 - accuracy: 0.8720 - val_loss: 1.2655 - val_accuracy: 0.7324\n","Epoch 13/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.7586 - accuracy: 0.8898 - val_loss: 1.2151 - val_accuracy: 0.7742\n","Epoch 14/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.6971 - accuracy: 0.9156 - val_loss: 1.2360 - val_accuracy: 0.7737\n","Epoch 15/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.6237 - accuracy: 0.9404 - val_loss: 1.1854 - val_accuracy: 0.7751\n","Epoch 16/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.5954 - accuracy: 0.9432 - val_loss: 1.1837 - val_accuracy: 0.7756\n","Epoch 17/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.5836 - accuracy: 0.9523 - val_loss: 1.2547 - val_accuracy: 0.7708\n","Epoch 18/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.5451 - accuracy: 0.9564 - val_loss: 1.2695 - val_accuracy: 0.7717\n","Epoch 19/32\n","193/193 [==============================] - 31s 163ms/step - loss: 0.5345 - accuracy: 0.9577 - val_loss: 1.2207 - val_accuracy: 0.7780\n","Epoch 20/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.5316 - accuracy: 0.9519 - val_loss: 1.2068 - val_accuracy: 0.7751\n","Epoch 21/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.5042 - accuracy: 0.9699 - val_loss: 1.2028 - val_accuracy: 0.7761\n","Epoch 22/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.5104 - accuracy: 0.9632 - val_loss: 1.1489 - val_accuracy: 0.7858\n","Epoch 23/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4935 - accuracy: 0.9667 - val_loss: 1.1595 - val_accuracy: 0.7771\n","Epoch 24/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4720 - accuracy: 0.9771 - val_loss: 1.1984 - val_accuracy: 0.7829\n","Epoch 25/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4565 - accuracy: 0.9777 - val_loss: 1.1834 - val_accuracy: 0.7844\n","Epoch 26/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4485 - accuracy: 0.9762 - val_loss: 1.2210 - val_accuracy: 0.7596\n","Epoch 27/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4740 - accuracy: 0.9649 - val_loss: 1.1675 - val_accuracy: 0.7882\n","Epoch 28/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4520 - accuracy: 0.9732 - val_loss: 1.2353 - val_accuracy: 0.7751\n","Epoch 29/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4325 - accuracy: 0.9778 - val_loss: 1.2567 - val_accuracy: 0.7766\n","Epoch 30/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4523 - accuracy: 0.9726 - val_loss: 1.2073 - val_accuracy: 0.7800\n","Epoch 31/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4642 - accuracy: 0.9627 - val_loss: 1.3104 - val_accuracy: 0.7703\n","Epoch 32/32\n","193/193 [==============================] - 31s 162ms/step - loss: 0.4767 - accuracy: 0.9629 - val_loss: 1.1466 - val_accuracy: 0.7858\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5p4QgrUJT6Mp"},"source":["# Dự Đoán các ảnh trên tập test\n","\n","Chúng ta sử dụng mô hình đã được huấn luyện bên trên để dự đoán cho các ảnh trong tập test, xuất ra file CSV và submit kết quả lên Kaggle:\n","\n","[Link nộp kết quả](https://www.kaggle.com/c/vietai-foundation-course-7-cnn-assignment)"]},{"cell_type":"markdown","metadata":{"id":"np3O0GgN4s3n"},"source":["## Tạo và load model đã lưu trước đó"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnnCTqhBT6Mq","executionInfo":{"elapsed":903,"status":"ok","timestamp":1614184042020,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"7427516c-ff84-4e14-d1f7-8e2c3e2681db"},"source":["# Load best model\n","model = CNN(num_classes)\n","\n","# Thiết lập kích thước input cho model\n","model.build(input_shape=(1,224,224,3))\n","\n","# Load model đã lưu trước đó trong quá trình huấn luyện\n","model.load_weights('my_model.h5')\n","print(\"Model đã được load\")\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model đã được load\n","Model: \"cnn_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv_block_10 (ConvBlock)    multiple                  896       \n","_________________________________________________________________\n","conv_block_11 (ConvBlock)    multiple                  18496     \n","_________________________________________________________________\n","conv_block_12 (ConvBlock)    multiple                  73856     \n","_________________________________________________________________\n","conv_block_13 (ConvBlock)    multiple                  295168    \n","_________________________________________________________________\n","conv_block_14 (ConvBlock)    multiple                  1180160   \n","_________________________________________________________________\n","flatten_2 (Flatten)          multiple                  0         \n","_________________________________________________________________\n","dense_4 (Dense)              multiple                  6554112   \n","_________________________________________________________________\n","dropout_2 (Dropout)          multiple                  0         \n","_________________________________________________________________\n","dense_5 (Dense)              multiple                  5643      \n","=================================================================\n","Total params: 8,128,331\n","Trainable params: 8,128,331\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QaMQvDMJ46Vs"},"source":["## Dự đoán nhãn của các ảnh trên tập test"]},{"cell_type":"markdown","metadata":{"id":"YLaGW2b55mqW"},"source":["Sử dụng hàm predict để dự đoán:"]},{"cell_type":"code","metadata":{"id":"TBl_-M0_T6Mt"},"source":["pred = model.predict(test_x)\n","\n","# pred là một ma trận xác suất của ảnh trên các lớp.\n","# Ta lấy lớp có xác suất cao nhất trên từng ảnh bằng hàm argmax\n","pred_labels = np.argmax(pred, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZqXMbQte5o7U"},"source":["Hiển thị thử kết quả của tập test:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"DhVAFRO3T6Nn","executionInfo":{"elapsed":900,"status":"ok","timestamp":1614184048561,"user":{"displayName":"duy tran","photoUrl":"","userId":"04501674580952687643"},"user_tz":-420},"outputId":"859e491a-38e0-48d9-8e9b-aceafdba2ab2"},"source":["test_df['label'] = pred_labels\n","test_df.head(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>VietAI-Assignment3-10.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>VietAI-Assignment3-1000.jpg</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>VietAI-Assignment3-10004.jpg</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>VietAI-Assignment3-10006.jpg</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>VietAI-Assignment3-10012.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>VietAI-Assignment3-10029.jpg</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>VietAI-Assignment3-10034.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>VietAI-Assignment3-10037.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>VietAI-Assignment3-1005.jpg</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>VietAI-Assignment3-10052.jpg</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>VietAI-Assignment3-10053.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>VietAI-Assignment3-10055.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>VietAI-Assignment3-10056.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>VietAI-Assignment3-10066.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>VietAI-Assignment3-10068.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>VietAI-Assignment3-1008.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>VietAI-Assignment3-10081.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>VietAI-Assignment3-10084.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>VietAI-Assignment3-10085.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>VietAI-Assignment3-10095.jpg</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           image  label\n","0      VietAI-Assignment3-10.jpg      1\n","1    VietAI-Assignment3-1000.jpg     10\n","2   VietAI-Assignment3-10004.jpg     10\n","3   VietAI-Assignment3-10006.jpg      5\n","4   VietAI-Assignment3-10012.jpg      2\n","5   VietAI-Assignment3-10029.jpg      4\n","6   VietAI-Assignment3-10034.jpg      2\n","7   VietAI-Assignment3-10037.jpg      2\n","8    VietAI-Assignment3-1005.jpg     10\n","9   VietAI-Assignment3-10052.jpg      4\n","10  VietAI-Assignment3-10053.jpg      3\n","11  VietAI-Assignment3-10055.jpg      3\n","12  VietAI-Assignment3-10056.jpg      2\n","13  VietAI-Assignment3-10066.jpg      2\n","14  VietAI-Assignment3-10068.jpg      1\n","15   VietAI-Assignment3-1008.jpg      1\n","16  VietAI-Assignment3-10081.jpg      2\n","17  VietAI-Assignment3-10084.jpg      3\n","18  VietAI-Assignment3-10085.jpg      2\n","19  VietAI-Assignment3-10095.jpg      1"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"QlJ9T6eN5u9n"},"source":["Lưu kết quả thành file CSV:"]},{"cell_type":"code","metadata":{"id":"wx7VJJnCozqu"},"source":["test_df.to_csv(\"submission.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLo6SJb-AjWD"},"source":["## Nộp kết quả lên Kaggle"]},{"cell_type":"markdown","metadata":{"id":"u9oGE4zfA5J9"},"source":["1. Truy cập vào [Kaggle](https://www.kaggle.com), đăng ký/ đăng nhập tài khoản.\n","\n","2. Truy cập vào đường dẫn của competition [VietAI Foundation Course - CNN Assignment](https://www.kaggle.com/c/vietai-foundation-course-7-cnn-assignment)\n","\n","3. Nhấn vào nút **Join Competition**.\n","![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.48.12.png)\n","\n","4. Nhấn vào nút **I Understand and Accept**.\n","![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.48.52.png)\n","\n","5. Chọn **Team**.\n","![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.49.43.png)\n","\n","6. Đặt team name theo đúng họ và tên của bạn và bấm **Save team name**.\n","![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.50.30.png)\n","\n","7. Để nộp file CSV vừa tạo, các bạn nhấp vào **Submit Predictions**.\n"," ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.51.39.png)\n"," \n","8. Upload file CSV và nộp.\n"," ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.52.19.png)\n","\n","9. Sau khi nộp, màn hình sẽ hiện ra kết quả, để biết vị trí mình trên leaderboard, các bạn nhấp vào **Jump to your position on the leaderboard**.\n"," ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.55.23.png)\n","\n","10. Leaderboard sẽ như sau:\n"," ![alt text](https://storage.googleapis.com/vietai/Screen%20Shot%202019-05-13%20at%2018.55.32.png)"]},{"cell_type":"markdown","metadata":{"id":"VB59gzvrksdZ"},"source":["# Thang điểm\n","\n","- Hoàn tất codes trên Notebook: 7đ\n","- Kaggle:\n","  \n","  + Vượt qua baseline1: 3đ\n","  + Vượt qua baseline2: +1đ\n","  + 5 bạn đứng đầu leaderboard của tập private test: +1đ"]},{"cell_type":"markdown","metadata":{"id":"9v5Pu5JEQfnc"},"source":["# Authors: Quoc Pham, Chuong Huynh"]}]}